# ETL Loader Module

Transform ë‹¨ê³„ì˜ ìµœì¢… ì¶œë ¥ë¬¼(JSONL)ì„ Parquet íŒŒì¼ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

## ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥

- **JSONL â†’ Parquet ë³€í™˜**: ì—¬ëŸ¬ JSONL íŒŒì¼ì„ í•˜ë‚˜ì˜ Parquet íŒŒì¼ë¡œ í†µí•©
- **ë°ì´í„° íƒ€ì… ìµœì í™”**: ë©”ëª¨ë¦¬ ë° ì €ì¥ ê³µê°„ íš¨ìœ¨í™”
- **íŒŒí‹°ì…”ë‹**: ê¸°ì—…ë³„, ë¬¸ì„œíƒ€ì…ë³„ë¡œ ë°ì´í„° ë¶„í•  ì €ì¥
- **ì••ì¶•**: Snappy, GZIP, ZSTD ë“± ë‹¤ì–‘í•œ ì••ì¶• ë°©ì‹ ì§€ì›

## ğŸš€ ì‚¬ìš©ë²•

### 1. ê¸°ë³¸ ì‚¬ìš© (ë‹¨ì¼ Parquet íŒŒì¼)

```bash
cd service/etl/loader
python jsonl_to_parquet.py
```

**ì…ë ¥**: `data/transform/final/*_chunks.jsonl`  
**ì¶œë ¥**: `data/parquet/chunks.parquet`

### 2. íŒŒí‹°ì…”ë‹ (ê¸°ì—…ë³„ ë¶„ë¦¬)

```bash
python jsonl_to_parquet.py --partition corp_name
```

**ì¶œë ¥**: `data/parquet/by_corp_name/corp_name={íšŒì‚¬ëª…}/`

### 3. ì••ì¶• ë°©ì‹ ë³€ê²½

```bash
python jsonl_to_parquet.py --compression zstd
```

**ì••ì¶• ì˜µì…˜**:

- `snappy`: ë¹ ë¥¸ ì••ì¶•/í•´ì œ (ê¸°ë³¸ê°’, ì¶”ì²œ)
- `gzip`: ë†’ì€ ì••ì¶•ë¥ 
- `zstd`: ê· í˜•ì¡íŒ ì••ì¶•ë¥ ê³¼ ì†ë„
- `brotli`: ìµœê³  ì••ì¶•ë¥  (ëŠë¦¼)

### 4. Python ì½”ë“œì—ì„œ ì‚¬ìš©

```python
from service.etl.loader import ParquetConverter
from pathlib import Path

# ë³€í™˜ê¸° ìƒì„±
converter = ParquetConverter(compression='snappy')

# JSONL íŒŒì¼ ì½ê¸°
input_dir = Path("data/transform/final")
jsonl_files = list(input_dir.glob("*_chunks.jsonl"))
df = converter.jsonl_to_dataframe(jsonl_files)

# Parquet ì €ì¥
output_path = Path("data/parquet/chunks.parquet")
converter.save_parquet(df, output_path)

# í†µê³„ ì •ë³´ í™•ì¸
stats = converter.get_parquet_stats(output_path)
print(f"ì´ {stats['num_rows']:,}ê°œ í–‰")
```

## ğŸ“Š Parquet íŒŒì¼ êµ¬ì¡°

### ìŠ¤í‚¤ë§ˆ

| ì»¬ëŸ¼ëª…          | íƒ€ì…     | ì„¤ëª…                        |
| --------------- | -------- | --------------------------- |
| chunk_id        | string   | ì²­í¬ ê³ ìœ  ID                |
| doc_id          | string   | ë¬¸ì„œ ID                     |
| chunk_type      | category | ì²­í¬ íƒ€ì… (text, table_row) |
| section_path    | string   | ì„¹ì…˜ ê²½ë¡œ                   |
| structured_data | object   | êµ¬ì¡°í™”ëœ ë°ì´í„° (ë”•ì…”ë„ˆë¦¬)  |
| natural_text    | string   | ìì—°ì–´ í…ìŠ¤íŠ¸               |
| metadata        | object   | ë©”íƒ€ë°ì´í„° (ë”•ì…”ë„ˆë¦¬)       |
| token_count     | int16    | í† í° ìˆ˜                     |

### ë©”íƒ€ë°ì´í„° í•„ë“œ

| í•„ë“œëª…        | íƒ€ì…     | ì„¤ëª…                |
| ------------- | -------- | ------------------- |
| corp_name     | string   | ê¸°ì—…ëª…              |
| document_name | string   | ë¬¸ì„œëª…              |
| rcept_dt      | string   | ì ‘ìˆ˜ì¼ì (YYYYMMDD) |
| doc_type      | category | ë¬¸ì„œ íƒ€ì…           |
| data_category | category | ë°ì´í„° ì¹´í…Œê³ ë¦¬     |
| fiscal_year   | int16    | ì‚¬ì—…ì—°ë„            |
| keywords      | list     | í‚¤ì›Œë“œ ëª©ë¡         |
| prev_context  | string   | ì´ì „ ë¬¸ë§¥           |
| next_context  | string   | ë‹¤ìŒ ë¬¸ë§¥           |

## ğŸ”§ íŒŒí‹°ì…”ë‹ ì „ëµ

### 1. ê¸°ì—…ë³„ íŒŒí‹°ì…”ë‹ (ì¶”ì²œ)

```bash
python jsonl_to_parquet.py --partition corp_name
```

**ì¥ì **:

- íŠ¹ì • ê¸°ì—… ë°ì´í„°ë§Œ ë¹ ë¥´ê²Œ ì¡°íšŒ
- ê¸°ì—…ë³„ ë¶„ì„ì— ìµœì í™”

**ì¶œë ¥ êµ¬ì¡°**:

```
data/parquet/by_corp_name/
â”œâ”€â”€ corp_name=ì‚¼ì„±ì „ì/
â”‚   â””â”€â”€ *.parquet
â”œâ”€â”€ corp_name=SKí•˜ì´ë‹‰ìŠ¤/
â”‚   â””â”€â”€ *.parquet
â””â”€â”€ ...
```

### 2. ë¬¸ì„œ íƒ€ì…ë³„ íŒŒí‹°ì…”ë‹

```bash
python jsonl_to_parquet.py --partition doc_type
```

**ì¥ì **:

- ë¬¸ì„œ íƒ€ì…ë³„ ë¶„ì„ (ì‚¬ì—…ë³´ê³ ì„œ, ë¶„ê¸°ë³´ê³ ì„œ ë“±)
- íƒ€ì…ë³„ í†µê³„ ë° í•„í„°ë§ íš¨ìœ¨í™”

### 3. ë°ì´í„° ì¹´í…Œê³ ë¦¬ë³„ íŒŒí‹°ì…”ë‹

```bash
python jsonl_to_parquet.py --partition data_category
```

**ì¥ì **:

- ì¬ë¬´, ì¼ë°˜ ë°ì´í„° ë¶„ë¦¬
- ì¹´í…Œê³ ë¦¬ë³„ ì„ë² ë”© ì „ëµ ì°¨ë³„í™”

## ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ

### íŒŒì¼ í¬ê¸° ë¹„êµ (ì˜ˆì‹œ: 10,000ê°œ ì²­í¬)

| í¬ë§·             | í¬ê¸°  | ì••ì¶•ë¥    |
| ---------------- | ----- | -------- |
| JSONL (ì›ë³¸)     | 50 MB | -        |
| Parquet (snappy) | 15 MB | 70% ê°ì†Œ |
| Parquet (gzip)   | 12 MB | 76% ê°ì†Œ |
| Parquet (zstd)   | 11 MB | 78% ê°ì†Œ |

### ì½ê¸° ì†ë„ ë¹„êµ

| í¬ë§·    | ì½ê¸° ì‹œê°„ | í•„í„°ë§ ì†ë„      |
| ------- | --------- | ---------------- |
| JSONL   | 2.5ì´ˆ     | ëŠë¦¼             |
| Parquet | 0.3ì´ˆ     | ë¹ ë¦„ (ì»¬ëŸ¼ ê¸°ë°˜) |

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

Parquet íŒŒì¼ ìƒì„± í›„:

1. **ì„ë² ë”© ìƒì„±**

   ```bash
   python embedding.py --input data/parquet/chunks.parquet
   ```

2. **pgvector ë¡œë“œ**

   ```bash
   python loader.py --input data/parquet/chunks.parquet
   ```

3. **Pandasë¡œ ë¶„ì„**
   ```python
   import pandas as pd
   df = pd.read_parquet("data/parquet/chunks.parquet")
   df.groupby('corp_name')['token_count'].sum()
   ```

## ğŸ› ï¸ ì˜ì¡´ì„±

```bash
pip install pandas pyarrow
```

## ğŸ“ ì°¸ê³ ì‚¬í•­

- ParquetëŠ” ì»¬ëŸ¼ ê¸°ë°˜ ì••ì¶• í¬ë§·ìœ¼ë¡œ ë°ì´í„° ë¶„ì„ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤
- íŒŒí‹°ì…”ë‹ì€ ë°ì´í„° í¬ê¸°ê°€ í° ê²½ìš°(100MB ì´ìƒ) ê¶Œì¥ë©ë‹ˆë‹¤
- Snappy ì••ì¶•ì€ ì†ë„ì™€ ì••ì¶•ë¥ ì˜ ê· í˜•ì´ ì¢‹ì•„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤
