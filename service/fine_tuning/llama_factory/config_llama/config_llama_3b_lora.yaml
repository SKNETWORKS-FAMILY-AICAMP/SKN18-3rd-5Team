# LLaMA-Factory training config (QLoRA SFT)

# ===== Stage & Model =====
stage: sft
model_name_or_path: meta-llama/Llama-3.2-3B
template: alpaca
cutoff_len: 4096

# ===== Data =====
dataset_dir: data
dataset: ko_report_summary_train
eval_dataset: ko_report_summary_eval

# ===== PEFT: LoRA =====
finetuning_type: lora
lora_target:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - gate_proj
  - up_proj
  - down_proj
lora_rank: 8
lora_alpha: 16
lora_dropout: 0.05

# ===== Quantization (QLoRA) =====
quantization_bit: 4

# ===== Training =====
output_dir: output/llama-3-2-3b-4bit/qlora
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 8
learning_rate: 1.0e-4
num_train_epochs: 3
lr_scheduler_type: cosine
warmup_ratio: 0.1

# ===== Eval & Save =====
do_train: true
do_eval: true
val_size: 0.0
eval_strategy: steps
eval_steps: 500
save_strategy: steps
save_steps: 500
save_total_limit: 3
save_only_model: true
load_best_model_at_end: true
metric_for_best_model: eval_loss
greater_is_better: false

# ===== System / Perf =====
fp16: true
bf16: false
gradient_checkpointing: true
flash_attn: fa2
packing: true
dataloader_num_workers: 4
dataloader_pin_memory: true
optim: adamw_torch
report_to:
  - tensorboard
seed: 42
