# RAG System - ëª¨ë“ˆ ê°€ì´ë“œ

ê¸ˆìœµ ë¬¸ì„œ ê²€ìƒ‰ ë° ìƒì„±ì„ ìœ„í•œ **Retrieval-Augmented Generation (RAG)** ì‹œìŠ¤í…œ

---

## ğŸ“ ëª¨ë“ˆ êµ¬ì¡°

```
service/rag/
â”œâ”€â”€ retrieval/          # ê²€ìƒ‰ ë° ì¬ì •ë ¬
â”‚   â”œâ”€â”€ retriever.py    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„°+í‚¤ì›Œë“œ)
â”‚   â””â”€â”€ eranker.py  # í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­ì»¤
â”‚
â”œâ”€â”€ augmentation/       # ì»¨í…ìŠ¤íŠ¸ ì¦ê°•
â”‚   â”œâ”€â”€ augmenter.py    # ë¬¸ì„œ ì •ë¦¬ ë° ì¦ê°•
â”‚   â””â”€â”€ formatters.py   # ì¶œë ¥ í¬ë§·í„° (Prompt/Markdown/JSON)
â”‚
â”œâ”€â”€ generation/         # LLM ë‹µë³€ ìƒì„± (ë‚´ë¶€ í…ŒìŠ¤íŠ¸ìš©)
â”‚   â””â”€â”€ generator.py    # Ollama ìƒì„±ê¸°
â”‚
â”œâ”€â”€ evaluation/         # ì„±ëŠ¥ í‰ê°€
â”‚   â”œâ”€â”€ ragas_evaluator.py         # RAGAs ë©”íŠ¸ë¦­
â”‚   â”œâ”€â”€ compare_retrieval_methods.py  # ê²€ìƒ‰ ë°©ë²• ë¹„êµ
â”‚   â”œâ”€â”€ evaluator.py    # í‰ê°€ ë„êµ¬
â”‚   â””â”€â”€ metrics.py      # í‰ê°€ ë©”íŠ¸ë¦­
â”‚
â”œâ”€â”€ models/             # ì„ë² ë”© ëª¨ë¸
â”‚   â”œâ”€â”€ encoder.py      # ì„ë² ë”© ì¸ì½”ë”
â”‚   â”œâ”€â”€ config.py       # ëª¨ë¸ ì„¤ì •
â”‚   â””â”€â”€ comparator.py   # ëª¨ë¸ ë¹„êµ
â”‚
â”œâ”€â”€ query/              # ì¿¼ë¦¬ ì²˜ë¦¬
â”‚   â””â”€â”€ temporal_parser.py  # ì‹œê°„ í‘œí˜„ íŒŒì‹±
â”‚
â”œâ”€â”€ vectorstore/        # ë²¡í„° DB
â”‚   â””â”€â”€ pgvector_store.py   # PostgreSQL + pgvector
â”‚
â”œâ”€â”€ cli/                # CLI ë„êµ¬
â”‚   â”œâ”€â”€ rag_cli.py                  # ê¸°ë³¸ ê²€ìƒ‰ CLI
â”‚   â”œâ”€â”€ rag_evaluation_tool.py      # í‰ê°€ ë„êµ¬
â”‚   â””â”€â”€ compare_embedding_models.py # ëª¨ë¸ ë¹„êµ
â”‚
â””â”€â”€ rag_system.py       # í†µí•© RAG ì‹œìŠ¤í…œ
```

---

## ğŸ” 1. Retrieval (ê²€ìƒ‰)

### `retrieval/retriever.py` - í†µí•© ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„

**ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰ + í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë¡œ í†µí•©**

#### ê²€ìƒ‰ ë°©ë²• 3ê°€ì§€

| ë°©ë²•        | ì„¤ëª…                        | ì¥ì              | ì‚¬ìš© ì‹œì   |
| ----------- | --------------------------- | ---------------- | ---------- |
| **vector**  | pgvector ì„ë² ë”© ìœ ì‚¬ë„      | ì˜ë¯¸ì  ìœ ì‚¬ì„±    | ê¸°ë³¸ ê²€ìƒ‰  |
| **keyword** | PostgreSQL Full-Text Search | ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ | ì¬ì‹œë„ 1ì°¨ |
| **hybrid**  | ë²¡í„° + í‚¤ì›Œë“œ ê²°í•© (RRF)    | ìµœê³  ì„±ëŠ¥        | ì¬ì‹œë„ 2ì°¨ |

```python
from service.rag.retrieval.retriever import Retriever
from service.rag.models.config import EmbeddingModelType

# ì´ˆê¸°í™”
retriever = Retriever(
    model_type=EmbeddingModelType.MULTILINGUAL_E5_SMALL,
    enable_temporal_filter=True,
    enable_hybrid=True  # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í™œì„±í™”
)

# 1. ë²¡í„° ê²€ìƒ‰ (ê¸°ë³¸)
results = retriever.search(
    query="ë°°í„°ë¦¬ ê¸°ìˆ ",
    top_k=10,
    search_method="vector"
)

# 2. í‚¤ì›Œë“œ ê²€ìƒ‰
results = retriever.search(
    query="ë°°í„°ë¦¬ ê¸°ìˆ ",
    top_k=10,
    search_method="keyword"
)

# 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ RRF)
results = retriever.search(
    query="ë°°í„°ë¦¬ ê¸°ìˆ ",
    top_k=10,
    search_method="hybrid"
)
```

**Rank Fusion ì•Œê³ ë¦¬ì¦˜**:

- **RRF (Reciprocal Rank Fusion)**: `score = Î£(1/(k+rank))`
- **Weighted Sum**: `score = w1 Ã— vector + w2 Ã— keyword`
- **Max Score**: ê° ë¬¸ì„œì˜ ìµœê³  ì ìˆ˜

---

## ğŸ¯ 2. Reranker (ì¬ì •ë ¬)

### `retrieval/reranker.py` - í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­ì»¤

**2ë‹¨ê³„ ë¦¬ë­í‚¹: Rule-based â†’ Cross-Encoder**

```
100ê°œ í›„ë³´ â†’ Rule-based (20ê°œ) â†’ Cross-Encoder (5ê°œ)
            âš¡ ë¹ ë¥¸ í•„í„°ë§       ğŸ¯ ì •ë°€ í‰ê°€
```

#### ë‚´ë¶€ êµ¬ì¡°

```
HybridReranker
â”œâ”€â”€ Stage 1: CombinedReranker (ìë™ í¬í•¨)
â”‚   â”œâ”€â”€ KeywordReranker (í‚¤ì›Œë“œ ë§¤ì¹­)
â”‚   â”œâ”€â”€ LengthReranker (ë¬¸ì„œ ê¸¸ì´)
â”‚   â””â”€â”€ PositionReranker (ë¬¸ì„œ ìœ„ì¹˜)
â”‚
â””â”€â”€ Stage 2: CrossEncoderReranker
    â””â”€â”€ BAAI/bge-reranker-v2-m3
```

#### ì‚¬ìš©ë²•

```python
from service.rag.retrieval.reranker import HybridReranker

# ê¸°ë³¸ ì‚¬ìš© (ëª¨ë“  ê¸°ëŠ¥ í¬í•¨)
reranker = HybridReranker(
    use_cross_encoder=True,        # Cross-Encoder ì‚¬ìš©
    stage1_top_k_multiplier=3.0    # Stage 1ì—ì„œ top_k Ã— 3ë°° ì„ íƒ
)

final_results = reranker.rerank(
    query="2ì°¨ì „ì§€ ì „ë§",
    candidates=search_results,
    top_k=5
)
```

#### ì˜µì…˜

```python
# Cross-Encoder ë„ê¸° (ë¹ ë¥¸ ì²˜ë¦¬)
reranker = HybridReranker(use_cross_encoder=False)
# â†’ Stage 1ë§Œ ì‚¬ìš© (Rule-basedë§Œ)

# ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš©
reranker = HybridReranker(
    cross_encoder_model="BAAI/bge-reranker-v2-m3",
    device="cuda"  # GPU ì‚¬ìš©
)
```

**ì„±ëŠ¥**:

- âœ… **ì •í™•ë„**: Cross-Encoder ìˆ˜ì¤€ (85-95%)
- âœ… **ì†ë„**: Stage 1 í•„í„°ë§ìœ¼ë¡œ ìµœì í™” (40-50ms)
- âœ… **ìœ ì—°ì„±**: Cross-Encoder ë„ê¸° ê°€ëŠ¥

---

## ğŸ“ 3. Augmentation (ì¦ê°•)

### `augmentation/augmenter.py` - ì»¨í…ìŠ¤íŠ¸ ì¦ê°•

**ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLM ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜**

```python
from service.rag.augmentation.augmenter import DocumentAugmenter
from service.rag.augmentation.formatters import PromptFormatter

augmenter = DocumentAugmenter(
    max_context_length=4000,
    max_documents=5
)

formatter = PromptFormatter()

augmented = augmenter.augment(
    query="ì§ˆë¬¸",
    search_results=ê²€ìƒ‰ê²°ê³¼,
    formatter=formatter
)

print(f"ì»¨í…ìŠ¤íŠ¸: {augmented.context_text}")
print(f"í† í° ìˆ˜: {augmented.token_count}")
print(f"ì¸ìš©: {augmented.citations}")
```

**ì²˜ë¦¬ ê³¼ì •**:

1. ì¤‘ë³µ ì œê±°
2. í† í° ì œí•œ
3. í¬ë§·íŒ…
4. ì¸ìš© ì •ë³´ ì¶”ì¶œ

---

### `augmentation/formatters.py` - í¬ë§·í„°

**3ê°€ì§€ ì¶œë ¥ í˜•ì‹**

```python
# 1. Prompt í˜•ì‹ (LLM ì…ë ¥ìš©)
from service.rag.augmentation.formatters import PromptFormatter
formatter = PromptFormatter()

# 2. Markdown í˜•ì‹ (ì‚¬ëŒ ê°€ë…ì„±)
from service.rag.augmentation.formatters import MarkdownFormatter
formatter = MarkdownFormatter()

# 3. JSON í˜•ì‹ (API ì‘ë‹µ)
from service.rag.augmentation.formatters import JSONFormatter
formatter = JSONFormatter()
```

---

## ğŸ¤– 4. Generation (ìƒì„±)

### íŒŒì¸íŠœë‹ëœ Llama 3.2 3B ëª¨ë¸ ì‚¬ìš©

**LangGraphì—ì„œëŠ” `service/llm/llm_client.py`ì˜ íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤**

âš ï¸ **ì£¼ì˜**: `service/rag/generation/generator.py`ëŠ” **ë‚´ë¶€ í…ŒìŠ¤íŠ¸ìš©**ì´ë¯€ë¡œ ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

#### ì‹¤ì œ ì‚¬ìš©: íŒŒì¸íŠœë‹ ëª¨ë¸

```python
from service.llm.llm_client import chat
from service.llm.prompt_templates import build_system_prompt, build_user_prompt

# 1. ì‚¬ìš©ì ë ˆë²¨ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
user_level = "intermediate"  # "beginner", "intermediate", "advanced"
system_prompt = build_system_prompt(user_level)
user_prompt = build_user_prompt(
    question="2ì°¨ì „ì§€ ì‚°ì—… ì „ë§ì€?",
    context="ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸...",
    level=user_level
)

# 2. íŒŒì¸íŠœë‹ëœ Llama 3.2 3B LoRA ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„±
answer = chat(
    system=system_prompt,
    user=user_prompt,
    max_tokens=512
)

print(f"ë‹µë³€: {answer}")
```

#### ì‚¬ìš©ì ë ˆë²¨ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

| ë ˆë²¨             | íŠ¹ì§•                            | ìš©ë„        |
| ---------------- | ------------------------------- | ----------- |
| **beginner**     | ì‰¬ìš´ ìš©ì–´, ì˜ˆì‹œ ì¤‘ì‹¬            | íˆ¬ì ì´ˆë³´ì |
| **intermediate** | ê· í˜•ì¡íŒ ì„¤ëª…, ì£¼ìš” ìˆ˜ì¹˜ í¬í•¨   | ì¼ë°˜ íˆ¬ìì |
| **advanced**     | ìƒì„¸ ìˆ˜ì¹˜, ì¶”ì„¸ ë¶„ì„, ë¬¸ì„œ ê·¼ê±° | ì „ë¬¸ íˆ¬ìì |

#### íŒŒì¸íŠœë‹ ëª¨ë¸ ì •ë³´

- **ë² ì´ìŠ¤ ëª¨ë¸**: Llama 3.2 3B
- **ì–´ëŒ‘í„°**: LoRA (Low-Rank Adaptation)
- **í•™ìŠµ ë°ì´í„°**: ê¸ˆìœµ ë¦¬í¬íŠ¸ QA ë°ì´í„°ì…‹
- **íŠ¹í™” ë¶„ì•¼**: í•œêµ­ ê¸ˆìœµ ë¬¸ì„œ ì´í•´ ë° ë‹µë³€ ìƒì„±

#### í…ŒìŠ¤íŠ¸ìš© Generator (ë‚´ë¶€ í…ŒìŠ¤íŠ¸ë§Œ ì‚¬ìš©)

```python
# âš ï¸ ì´ ì½”ë“œëŠ” í…ŒìŠ¤íŠ¸ìš©ì…ë‹ˆë‹¤. LangGraphì—ì„œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
from service.rag.generation.generator import OllamaGenerator

generator = OllamaGenerator(
    base_url="http://localhost:11434",
    default_model="gemma2:2b"
)

# Ollamaë¥¼ ì‚¬ìš©í•œ ë¡œì»¬ í…ŒìŠ¤íŠ¸
answer = generator.generate(
    query="í…ŒìŠ¤íŠ¸ ì§ˆë¬¸",
    context="í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸..."
)
```

---

## ğŸ“Š 5. Evaluation (í‰ê°€)

### `evaluation/ragas_evaluator.py` - RAG í’ˆì§ˆ í‰ê°€

**RAGAs ë©”íŠ¸ë¦­ìœ¼ë¡œ RAG ì‹œìŠ¤í…œ í‰ê°€**

#### 4ê°€ì§€ ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­                | í‰ê°€ ëŒ€ìƒ | ì§ˆë¬¸                         |
| --------------------- | --------- | ---------------------------- |
| **Faithfulness**      | ë‹µë³€      | ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•˜ëŠ”ê°€?       |
| **Answer Relevancy**  | ë‹µë³€      | ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ”ê°€?           |
| **Context Precision** | ê²€ìƒ‰      | ì •í™•í•œ ë¬¸ì„œë¥¼ ì°¾ì•˜ëŠ”ê°€?      |
| **Context Recall**    | ê²€ìƒ‰      | í•„ìš”í•œ ì •ë³´ë¥¼ ëª¨ë‘ ì°¾ì•˜ëŠ”ê°€? |

```python
from service.rag.evaluation.ragas_evaluator import RAGASEvaluator

evaluator = RAGASEvaluator()

evaluation = evaluator.evaluate(
    query="2ì°¨ì „ì§€ ì‚°ì—… ì „ë§ì€?",
    answer="2ì°¨ì „ì§€ ì‚°ì—…ì€ ì „ê¸°ì°¨ ìˆ˜ìš”ë¡œ ì„±ì¥ ì „ë§ì…ë‹ˆë‹¤.",
    contexts=["ì»¨í…ìŠ¤íŠ¸ 1", "ì»¨í…ìŠ¤íŠ¸ 2"],
    ground_truth="ì˜ˆìƒ ë‹µë³€ (ì„ íƒì‚¬í•­)"
)

print(f"Faithfulness:       {evaluation.faithfulness:.3f}")
print(f"Answer Relevancy:   {evaluation.answer_relevancy:.3f}")
print(f"Context Precision:  {evaluation.context_precision:.3f}")
print(f"Average Score:      {evaluation.average_score:.3f}")
```

---

### `evaluation/compare_retrieval_methods.py` - ê²€ìƒ‰ ë°©ë²• ë¹„êµ

**Vector vs Keyword vs Hybrid ì„±ëŠ¥ ë¹„êµ**

```python
from service.rag.evaluation.compare_retrieval_methods import (
    RetrievalComparisonExperiment
)

experiment = RetrievalComparisonExperiment(db_config)
await experiment.initialize()

# ë¹„êµ ì‹¤í—˜ ìˆ˜í–‰
results_df = await experiment.compare_methods(
    test_queries=[
        {'query': 'ì§ˆë¬¸1', 'embedding': [...]},
        {'query': 'ì§ˆë¬¸2', 'embedding': [...]}
    ],
    top_k=5,
    use_reranker=True
)

# ê²°ê³¼ ë¶„ì„
analysis = experiment.analyze_results(results_df)
experiment.save_results(results_df, analysis)
```

**ì¶œë ¥**: CSV + JSON íŒŒì¼ (ì†ë„, ì •í™•ë„ ë¹„êµ)

---

## ğŸ¨ 6. Models (ì„ë² ë”© ëª¨ë¸)

### `models/encoder.py` - ì„ë² ë”© ëª¨ë¸

**3ê°€ì§€ ì„ë² ë”© ëª¨ë¸ ì§€ì›**

| ëª¨ë¸                  | ì°¨ì› | íŠ¹ì§•         |
| --------------------- | ---- | ------------ |
| **E5-Small**          | 384  | ë¹ ë¦„, ë‹¤êµ­ì–´ |
| **KakaoBank DeBERTa** | 768  | í•œêµ­ì–´ ê¸ˆìœµ  |
| **FinE5**             | 4096 | ê¸ˆìœµ íŠ¹í™”    |

```python
from service.rag.models.encoder import get_encoder
from service.rag.models.config import EmbeddingModelType

# ì¸ì½”ë” ë¡œë“œ
encoder = get_encoder(EmbeddingModelType.MULTILINGUAL_E5_SMALL)

# ì¿¼ë¦¬ ì„ë² ë”©
query_emb = encoder.encode_query("2ì°¨ì „ì§€ ì‚°ì—…")

# ë¬¸ì„œ ì„ë² ë”© (ë°°ì¹˜)
doc_embs = encoder.encode_documents(["ë¬¸ì„œ1", "ë¬¸ì„œ2"])

# ë²¡í„° ì°¨ì›
print(f"ì°¨ì›: {encoder.get_dimension()}")
```

---

## ğŸ§© 7. Query (ì¿¼ë¦¬ ë¶„ì„)

### `query/temporal_parser.py` - ì‹œê°„ í‘œí˜„ íŒŒì‹±

**ì¿¼ë¦¬ì—ì„œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ**

```python
from service.rag.query.temporal_parser import parse_temporal_query

# ì˜ˆì‹œ 1
result = parse_temporal_query("2024ë…„ 2ë¶„ê¸° ì‹¤ì ì€?")
# â†’ {'year': 2024, 'quarter': 2}

# ì˜ˆì‹œ 2
result = parse_temporal_query("ì‘ë…„ 12ì›” ë§¤ì¶œì€?")
# â†’ {'year': 2024, 'month': 12}
```

**ìš©ë„**: ì‹œê³„ì—´ ë°ì´í„° í•„í„°ë§

---

## ğŸ—„ï¸ 8. VectorStore (ë²¡í„° DB)

### `vectorstore/pgvector_store.py` - PostgreSQL + pgvector

**ë²¡í„° ë°ì´í„° ì €ì¥ ë° ê²€ìƒ‰**

```python
from service.rag.vectorstore.pgvector_store import PGVectorStore

store = PGVectorStore(db_config)

# ì„ë² ë”© ì‚½ì…
await store.insert_embeddings([
    {'chunk_id': 'id1', 'embedding': [...], 'metadata': {...}},
    {'chunk_id': 'id2', 'embedding': [...], 'metadata': {...}}
])

# ìœ ì‚¬ ê²€ìƒ‰
results = await store.search_similar(
    embedding=query_embedding,
    top_k=10,
    min_similarity=0.7
)

# HNSW ì¸ë±ìŠ¤ ìƒì„±
await store.create_index()
```

---

## ğŸ”„ Self-RAG / Corrective RAG

### ê°œë…: ë‹µë³€ í’ˆì§ˆ ê²€ì¦ í›„ ì¬ê²€ìƒ‰

**ë¬¸ì œ**: ì²« ê²€ìƒ‰ìœ¼ë¡œ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ëª» ì°¾ìœ¼ë©´?
**í•´ê²°**: ë‹µë³€ì„ ê²€ì¦í•˜ê³ , í’ˆì§ˆì´ ë‚®ìœ¼ë©´ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì¬ê²€ìƒ‰

### ì‘ë™ ë°©ì‹

```
1. Retrieve (Vector) â†’ ë¬¸ì„œ ê²€ìƒ‰
2. Rerank â†’ ì¬ì •ë ¬
3. Generate â†’ ë‹µë³€ ìƒì„±
4. GroundingCheck â†’ [ref:] ìˆëŠ”ì§€ ê²€ì¦
   â”œâ”€ âœ… ì„±ê³µ â†’ Guardrailë¡œ ì§„í–‰
   â””â”€ âŒ ì‹¤íŒ¨ â†’ Retrieveë¡œ ì¬ì‹œë„ (ìµœëŒ€ 1íšŒ)
                (Vector ì‹¤íŒ¨ â†’ Keywordë¡œ ì¬ê²€ìƒ‰)
```

### êµ¬í˜„ ìœ„ì¹˜

- **LangGraph**: `graph/nodes/grounding_check.py`
- **ë¡œì§**: ë‹µë³€ì— `[ref:]` ì—†ìœ¼ë©´ ì¬ì‹œë„
- **ì°¸ê³ **: `graph/readme.md` (retry ì—£ì§€)

### í™•ì¥ ì˜ˆì‹œ

```python
# graph/nodes/grounding_check.py í™•ì¥ ì•„ì´ë””ì–´
def run(state: QAState) -> QAState:
    grounded = "[ref:" in state.get("draft_answer", "")

    if not grounded and state.get("retry_count", 0) < 1:
        # ì¬ê²€ìƒ‰ ì „ëµ ë³€ê²½
        if state["search_method"] == "vector":
            state["search_method"] = "keyword"  # Vector â†’ Keyword
        elif state["search_method"] == "keyword":
            state["search_method"] = "hybrid"   # Keyword â†’ Hybrid

        state["retry_count"] = state.get("retry_count", 0) + 1
        # Retrieve ë…¸ë“œë¡œ ëŒì•„ê°

    state["grounded"] = grounded
    return state
```

---

## ğŸ“– ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ

```python
from service.rag.rag_system import RAGSystem
from service.rag.models.config import EmbeddingModelType

# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
rag = RAGSystem(
    model_type=EmbeddingModelType.MULTILINGUAL_E5_SMALL,
    enable_generation=True
)

# ê²€ìƒ‰ + ì¦ê°•
response = rag.retrieve_and_augment(
    query="2ì°¨ì „ì§€ ì‚°ì—… ì „ë§ì€?",
    top_k=5,
    use_reranker=True
)

print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(response.retrieved_documents)}ê°œ")
print(f"ì»¨í…ìŠ¤íŠ¸: {response.augmented_context.token_count} í† í°")

# ì „ì²´ RAG (ê²€ìƒ‰ + ìƒì„±)
full_response = rag.generate_answer(
    query="2ì°¨ì „ì§€ ì‚°ì—… ì „ë§ì€?",
    top_k=5
)

print(f"ë‹µë³€: {full_response.generated_answer.answer}")
```

---

## ğŸ› ï¸ CLI ì‚¬ìš©ë²•

### ê¸°ë³¸ ê²€ìƒ‰

```bash
cd service/rag/cli

# ê¸°ë³¸ ê²€ìƒ‰
python rag_cli.py search --query "ì‚¼ì„±ì „ì ë§¤ì¶œ"

# ìƒìœ„ 10ê°œ ê²°ê³¼
python rag_cli.py search --query "ë§¤ì¶œ ì¦ê°€" --top-k 10

# íŠ¹ì • ê¸°ì—…ë§Œ ê²€ìƒ‰
python rag_cli.py search --query "ì—°êµ¬ê°œë°œë¹„" --corp-filter "ì‚¼ì„±ì „ì"

# ìµœì†Œ ìœ ì‚¬ë„ ì„¤ì •
python rag_cli.py search --query "AI ê¸°ìˆ " --min-similarity 0.7
```

### RAG í‰ê°€

```bash
# ê¸°ë³¸ í‰ê°€
python rag_evaluation_tool.py --top-k 3

# íŠ¹ì • ê¸°ì—… í‰ê°€
python rag_evaluation_tool.py --corp-filter "ì‚¼ì„±ì „ì" --top-k 5

# ë‹¤ë¥¸ ëª¨ë¸ë¡œ í‰ê°€
python rag_evaluation_tool.py --model kakaobank --top-k 3
```

### í†µê³„ í™•ì¸

```bash
python rag_cli.py stats
```

---

## ğŸ¯ í•µì‹¬ í•¨ìˆ˜ ìš”ì•½í‘œ

| ëª¨ë“ˆ               | í´ë˜ìŠ¤/í•¨ìˆ˜                | ê¸°ëŠ¥                                        |
| ------------------ | -------------------------- | ------------------------------------------- |
| **Retriever**      | `Retriever.search(method)` | í†µí•© ê²€ìƒ‰ (vector/keyword/hybrid ì„ íƒ ê°€ëŠ¥) |
| **Reranker**       | `HybridReranker.rerank()`  | 2ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­í‚¹                     |
| **Augmenter**      | `augment(q, res, fmt)`     | ì»¨í…ìŠ¤íŠ¸ ì¦ê°•                               |
| **Generator**      | `generate(q, ctx)`         | ë‹µë³€ ìƒì„±                                   |
| **RAGASEvaluator** | `evaluate(q, a, ctx)`      | RAG í‰ê°€                                    |
| **Encoder**        | `encode_query(text)`       | ì„ë² ë”© ìƒì„±                                 |
| **TemporalParser** | `parse_temporal_query(q)`  | ì‹œê°„ íŒŒì‹±                                   |

---

## ğŸ“š ì¶”ê°€ ìë£Œ

- **LangGraph í†µí•©**: `/graph/readme.md`
- **ëª¨ë“ˆ ìƒì„¸ ë¬¸ì„œ**: `/service/rag/MODULES_README.md`

---

**ì‘ì„±ì¼**: 2025-01-26
**ë²„ì „**: 3.0
