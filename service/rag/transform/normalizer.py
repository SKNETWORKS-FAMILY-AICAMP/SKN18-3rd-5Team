#!/usr/bin/env python3
"""
====================================================================================
Transform Pipeline - Step 2: ë°ì´í„° ì •ê·œí™” ë° ìì—°ì–´ í’ˆì§ˆ ê°œì„ 
====================================================================================

[íŒŒì´í”„ë¼ì¸ ìˆœì„œ]
1. structured.py      â†’ ë§ˆí¬ë‹¤ìš´ì„ êµ¬ì¡°í™”ëœ ì²­í¬ë¡œ ë³€í™˜
2. data_normalizer.py â†’ ë°ì´í„° ì •ê·œí™” ë° ìì—°ì–´ í’ˆì§ˆ ê°œì„  (í˜„ì¬ íŒŒì¼)
3. chunker.py         â†’ ìŠ¤ë§ˆíŠ¸ ì²­í‚¹ ë° ë©”íƒ€ë°ì´í„° ê°•í™”

[ì´ íŒŒì¼ì˜ ì—­í• ]
- ë‚ ì§œ í˜•ì‹ í†µì¼ (YYYY-MM-DD)
- í†µí™” ë‹¨ìœ„ í‘œì¤€í™” (ì–µì› ë³€í™˜)
- ëª©ì°¨ ë° ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œê±°
- ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì •ë¦¬
- ìì—°ì–´ í’ˆì§ˆ ê°œì„  (ë°˜ë³µ ì¶•ì†Œ, ë¬¸ë§¥ ì¶”ê°€)

[ì…ë ¥]
- data/transform/structured/*_chunks.jsonl (structured.py ì¶œë ¥)

[ì¶œë ¥]
- data/transform/normalized/*_chunks.jsonl (ì •ê·œí™”ëœ ì²­í¬)
====================================================================================
"""

import re
import json
import math
from datetime import datetime
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass
import unicodedata

try:
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    LANGCHAIN_AVAILABLE = True
except ImportError:
    try:
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        LANGCHAIN_AVAILABLE = True
    except ImportError:
        LANGCHAIN_AVAILABLE = False
        RecursiveCharacterTextSplitter = None
        print("âš ï¸  LangChain not available. Text chunks will not be split further.")


@dataclass
class NormalizationConfig:
    """ì •ê·œí™” ì„¤ì •"""
    # ë‚ ì§œ í˜•ì‹ (ISO 8601)
    date_format: str = "%Y-%m-%d"
    
    # í†µí™” ë‹¨ìœ„ ê¸°ì¤€ (ì–µì›)
    currency_unit_threshold: int = 100_000_000
    
    # ì œê±°í•  íŒ¨í„´
    remove_patterns: List[str] = None
    
    def __post_init__(self):
        if self.remove_patterns is None:
            self.remove_patterns = [
                r'\*\*ëª©\s+ì°¨\*\*.*?(?=\n\n|\Z)',  # ëª©ì°¨ (ë§ˆí¬ë‹¤ìš´)
                r'I+\.\s+[ê°€-í£\s]+â€¥+\s*\d+',  # ë¡œë§ˆ ìˆ«ì ëª©ì°¨
                r'ì œ\s*\d+\s*\([ì „ë‹¹]*\)\s*ê¸°',  # ì¤‘ë³µ ê¸°ìˆ˜ í‘œì‹œ
                # ìƒì„¸í•œ ëª©ì°¨ íŒ¨í„´
                r'ã€[^ã€‘]*ã€‘\s*-+\s*\d+',  # ã€ ì œëª© ã€‘ -------- í˜ì´ì§€ë²ˆí˜¸
                # ëª©ì°¨ ë¸”ë¡ ì „ì²´ ì œê±° (ë¡œë§ˆìˆ«ì/ì•„ë¼ë¹„ì•„ìˆ«ì + ì œëª© + ì ì„  + í˜ì´ì§€ë²ˆí˜¸)
                r'(?:^|\n)(?:[IVX]+\.|[0-9\-\.]+)\s+[ê°€-í£\s\(\)]+\s+-+\s*\d+(?:\n[IVX0-9\-\.]+\s+[ê°€-í£\s\(\)]+\s+-+\s*\d+)*',
            ]


class DataNormalizer:
    """ë°ì´í„° ì •ê·œí™” ì²˜ë¦¬"""
    
    def __init__(self, config: NormalizationConfig = None):
        self.config = config or NormalizationConfig()
    
    def normalize_chunk(self, chunk: Dict[str, Any]) -> Union[Dict[str, Any], List[Dict[str, Any]]]:
        """ì²­í¬ ë‹¨ìœ„ ì •ê·œí™”

        Returns:
            ë‹¨ì¼ chunk ë˜ëŠ” text íƒ€ì…ì¸ ê²½ìš° ë¶„í• ëœ chunk ë¦¬ìŠ¤íŠ¸
        """

        # structured_data ì •ê·œí™” ë¨¼ì € (natural_text ìƒì„±ì— ì‚¬ìš©ë¨)
        if chunk.get('structured_data'):
            chunk['structured_data'] = self._normalize_structured_data(
                chunk['structured_data']
            )

        # structured_data ì¬êµ¬ì„± (ë¹ˆ ê°’ì´ ë§ì€ ê²½ìš°)
        if chunk.get('chunk_type') == 'table_row' and chunk.get('structured_data'):
            section = chunk.get('section_path', '')
            if any(kw in section.replace(' ', '') for kw in ['ì¬ë¬´', 'ì†ìµ', 'ìì‚°', 'ì¬ë¬´ì œí‘œ']):
                has_financial_data = any(
                    v and v != '-'
                    for k, v in chunk['structured_data'].items()
                    if isinstance(v, str) and ('ê¸°ë§' in k or 'ê¸°ì´ˆ' in k or 'ë…„' in k or 'ë¶„ê¸°' in k)
                )
                if not has_financial_data and chunk.get('natural_text'):
                    chunk['structured_data'] = self._reconstruct_structured_from_text(chunk['natural_text'])

        # natural_text ê°œì„ 
        if chunk.get('natural_text'):
            chunk['natural_text'] = self._improve_natural_text(
                chunk['natural_text'],
                chunk.get('chunk_type'),
                chunk.get('structured_data', {}),
                chunk.get('metadata', {}),
                chunk.get('section_path', '')
            )

        # text íƒ€ì… ì²­í¬ëŠ” LangChain splitterë¡œ ë¶„í• 
        if chunk.get('chunk_type') == 'text' and LANGCHAIN_AVAILABLE:
            return self._split_text_chunk(chunk)

        return chunk

    def _split_text_chunk(self, chunk: Dict[str, Any]) -> List[Dict[str, Any]]:
        """text íƒ€ì… ì²­í¬ë¥¼ LangChain splitterë¡œ ë¶„í• 

        ì ì‘í˜• chunk_size ì‚¬ìš©: max(300, min(1000, ceil(total_length // 30)))
        """
        text = chunk.get('natural_text', '')
        if not text or len(text) < 200:
            # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ë¶„í• í•˜ì§€ ì•ŠìŒ
            return [chunk]

        # ì ì‘í˜• chunk_size ê³„ì‚°
        total_length = len(text)
        chunk_size = max(300, min(1000, math.ceil(total_length / 30)))
        chunk_overlap = min(50, chunk_size // 5)

        # LangChain splitter ìƒì„±
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            is_separator_regex=False,
        )

        # í…ìŠ¤íŠ¸ ë¶„í• 
        split_texts = text_splitter.split_text(text)

        # ë¶„í• ëœ í…ìŠ¤íŠ¸ë¡œ chunk ìƒì„±
        result_chunks = []
        base_chunk_id = chunk.get('chunk_id', '')

        for idx, split_text in enumerate(split_texts):
            new_chunk = chunk.copy()
            new_chunk['natural_text'] = split_text
            # chunk_idì— ë¶„í•  ì¸ë±ìŠ¤ ì¶”ê°€
            if '_split_' in base_chunk_id:
                # ì´ë¯¸ ë¶„í• ëœ ê²½ìš° ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¡œ êµì²´
                new_chunk['chunk_id'] = re.sub(r'_split_\d+$', f'_split_{idx}', base_chunk_id)
            else:
                new_chunk['chunk_id'] = f"{base_chunk_id}_split_{idx}"

            # metadataì— ë¶„í•  ì •ë³´ ì¶”ê°€
            if 'metadata' not in new_chunk:
                new_chunk['metadata'] = {}
            new_chunk['metadata']['split_index'] = idx
            new_chunk['metadata']['total_splits'] = len(split_texts)
            new_chunk['metadata']['chunk_size'] = chunk_size

            result_chunks.append(new_chunk)

        return result_chunks

    def _improve_natural_text(
        self, 
        text: str, 
        chunk_type: str,
        structured_data: Dict,
        metadata: Dict,
        section_path: str = ""
    ) -> str:
        """ìì—°ì–´ í’ˆì§ˆ ê°œì„ """
        
        # 1. ëª©ì°¨ ë° ë¶ˆí•„ìš” íŒ¨í„´ ì œê±°
        text = self._remove_unnecessary_content(text)
        
        # 2. ë§ˆí¬ë‹¤ìš´ ì œê±°
        text = self._clean_markdown(text)
        
        # 3. íƒ€ì…ë³„ ì²˜ë¦¬
        if chunk_type == 'table_row':
            text = self._improve_table_text(text, structured_data, metadata, section_path)
        elif chunk_type == 'text':
            text = self._improve_text_content(text, metadata, section_path)
        
        # 4. ê³µë°± ì •ë¦¬
        text = self._normalize_whitespace(text)
        
        return text
    
    def _remove_unnecessary_content(self, text: str) -> str:
        """ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œê±°"""
        
        # ëª©ì°¨ ì œê±°
        for pattern in self.config.remove_patterns:
            text = re.sub(pattern, '', text, flags=re.DOTALL)
        
        # í˜ì´ì§€ ë²ˆí˜¸ ì œê±°
        text = re.sub(r'^\s*\d+\s*$', '', text, flags=re.MULTILINE)
        
        # ê³¼ë„í•œ ì ì„  ì œê±°
        text = re.sub(r'â€¥{3,}', '', text)
        
        return text
    
    def _clean_markdown(self, text: str) -> str:
        """ë§ˆí¬ë‹¤ìš´ ì •ë¦¬"""
        
        # Bold ì œê±°
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
        
        # Italic ì œê±°
        text = re.sub(r'\*([^*]+)\*', r'\1', text)
        
        return text
    
    def _improve_table_text(
        self,
        text: str,
        structured_data: Dict,
        metadata: Dict,
        section_path: str = ""
    ) -> str:
        """í…Œì´ë¸” ìì—°ì–´ ê°œì„  - ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ìƒì„±"""

        section = section_path

        # 1. structured_data ê¸°ë°˜ ìì—°ì–´ ë¬¸ì¥ ìƒì„± (ìš°ì„ ìˆœìœ„ 1)
        natural_sentence = self._generate_natural_sentence(structured_data, section, metadata)
        if natural_sentence:
            return natural_sentence

        # 2. ë°˜ë³µ ì œê±° ë° ê¸°ë³¸ ê°œì„ 
        text = self._reduce_repetition(text)

        # 3. ì¬ë¬´ì œí‘œ íŠ¹í™” ì²˜ë¦¬ (ê³µë°± ì œê±° í›„ ì²´í¬)
        if any(kw in section.replace(' ', '') for kw in ['ì¬ë¬´', 'ì†ìµ', 'ìì‚°', 'ì¬ë¬´ì œí‘œ']):
            text = self._improve_financial_text(text, structured_data)

        # 4. ì£¼ì‹ ì •ë³´ íŠ¹í™” ì²˜ë¦¬
        elif 'ì£¼ì‹' in section:
            text = self._improve_stock_text(text, structured_data)

        # 5. ë‚ ì§œ ì •ê·œí™”
        text = self._normalize_dates_in_text(text)

        return text

    def _reconstruct_structured_from_text(self, text: str) -> Dict[str, str]:
        """natural_textì—ì„œ structured_data ì¬êµ¬ì„±"""
        data = {}

        # "í‚¤: ê°’, í‚¤: ê°’" í˜•íƒœ íŒŒì‹±
        pairs = text.split(', ')
        for pair in pairs:
            if ': ' in pair:
                key, value = pair.split(': ', 1)
                data[key.strip()] = value.strip()

        return data
    
    def _generate_natural_sentence(self, data: Dict, section: str, metadata: Dict) -> str:
        """ì„¹ì…˜ë³„ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ìƒì„±"""

        if not data:
            return ""

        # 0. ìê¸°ì£¼ì‹ ì·¨ë“ (ìµœìš°ì„ )
        if 'ìê¸°ì£¼ì‹' in section and ('ì·¨ë“' in section or 'ì‹ íƒ' in section):
            return self._generate_treasury_stock_sentence(data, metadata)

        # 1. ì‹ ìš©í‰ê°€ (í‚¤ ê¸°ë°˜ ê°ì§€ ì¶”ê°€)
        elif 'ì‹ ìš©í‰ê°€' in section or 'ì‹ ìš©ë“±ê¸‰' in data or 'ì‹ ìš©í‰ê°€ê¸°ê´€' in data:
            return self._generate_credit_rating_sentence(data, metadata)

        # 2. ì‚¬ì—…ì—°ë„ ì •ë³´ (ìƒˆë¡œ ì¶”ê°€) - í‚¤ ê²€ìƒ‰ìœ¼ë¡œ ìˆ˜ì •
        elif any('ì‚¬ì—…ì—°ë„' in k for k in data.keys()) or any('ë…„' in k and 'ì›”' in k and 'ì¼' in k for k in data.keys()):
            sentence = self._generate_fiscal_period_sentence(data, metadata)
            if sentence:
                return sentence

        # 3. ì¤‘ì†Œ/ì¤‘ê²¬ê¸°ì—… ì—¬ë¶€ (ìƒˆë¡œ ì¶”ê°€) - í‚¤ì™€ ê°’ ëª¨ë‘ ê²€ìƒ‰
        elif (any('ì¤‘ì†Œê¸°ì—…' in k or 'ì¤‘ê²¬ê¸°ì—…' in k or 'ë²¤ì²˜ê¸°ì—…' in k for k in data.keys()) or
              any('ì¤‘ì†Œê¸°ì—…' in v or 'ì¤‘ê²¬ê¸°ì—…' in v or 'ë²¤ì²˜ê¸°ì—…' in v for v in data.values() if isinstance(v, str))):
            sentence = self._generate_company_classification_sentence(data, metadata)
            if sentence:
                return sentence

        # 4. ì¬ë¬´ì œí‘œ (ê³µë°± ì œê±° í›„ ì²´í¬)
        elif any(keyword in section.replace(' ', '') for keyword in ['ì¬ë¬´', 'ì†ìµ', 'ìì‚°', 'ë¶€ì±„', 'ì¬ë¬´ì œí‘œ']):
            return self._generate_financial_sentence(data, metadata)

        # 5. ì£¼ì‹ ì •ë³´
        elif 'ì£¼ì‹' in section:
            return self._generate_stock_sentence(data, metadata)

        # 6. ë°°ë‹¹ ì •ë³´
        elif 'ë°°ë‹¹' in section:
            return self._generate_dividend_sentence(data, metadata)

        # 7. ì„ì› ì •ë³´
        elif 'ì„ì›' in section or 'ì´ì‚¬' in section:
            return self._generate_executive_sentence(data, metadata)

        return ""
    
    def _generate_treasury_stock_sentence(self, data: Dict, metadata: Dict) -> str:
        """ìê¸°ì£¼ì‹ ì·¨ë“ ìì—°ì–´ ë¬¸ì¥ ìƒì„±"""
        company = metadata.get('corp_name', 'íšŒì‚¬')
        doc_name = metadata.get('document_name', '')
        
        # ë°ì´í„° ì¶”ì¶œ
        contract_amount = None
        start_date = None
        end_date = None
        purpose = None
        broker = None
        decision_date = None
        shares_before = None
        shares_ratio = None
        
        # í‚¤ ë§¤ì¹­ (ë‹¤ì–‘í•œ í‘œí˜„ ëŒ€ì‘)
        for key, value in data.items():
            key_lower = key.lower().replace(' ', '')
            
            # ê³„ì•½ê¸ˆì•¡
            if 'ê³„ì•½ê¸ˆì•¡' in key or 'ê¸ˆì•¡' in key:
                if value and value != '-' and value.replace(',', '').isdigit():
                    contract_amount = self._format_financial_amount(value)
            
            # ì‹œì‘ì¼
            elif 'ì‹œì‘ì¼' in key or 'ê°œì‹œ' in key:
                start_date = self._normalize_dates_in_text(str(value))
            
            # ì¢…ë£Œì¼
            elif 'ì¢…ë£Œì¼' in key or 'ë§Œë£Œ' in key:
                end_date = self._normalize_dates_in_text(str(value))
            
            # ëª©ì 
            elif 'ëª©ì ' in key or 'ìš©ë„' in key:
                purpose = value
            
            # ì¦ê¶Œì‚¬/ì¤‘ê°œì—…ì
            elif 'ì²´ê²°ê¸°ê´€' in key or 'ì¤‘ê°œì—…ì' in key or 'ì¦ê¶Œ' in key:
                broker = value
            
            # ê²°ì •ì¼
            elif 'ê²°ì •ì¼' in key or 'ì˜ˆì •ì¼ì' in key:
                decision_date = self._normalize_dates_in_text(str(value))
            
            # ë³´ìœ  ì£¼ì‹ìˆ˜
            elif 'ë³´í†µì£¼ì‹' in key and value and value.replace(',', '').isdigit():
                shares_before = self._format_number_with_unit(value, 'ì£¼')
            
            # ë³´ìœ  ë¹„ìœ¨
            elif 'ë¹„ìœ¨' in key and value and value != '-':
                shares_ratio = value if '%' in str(value) else f"{value}%"
        
        # ìì—°ì–´ ë¬¸ì¥ ìƒì„±
        parts = []
        
        # ê¸°ë³¸ ë¬¸ì¥
        if decision_date:
            parts.append(f"{company}ëŠ” {decision_date}ì— ìê¸°ì£¼ì‹ ì·¨ë“ ì‹ íƒê³„ì•½ ì²´ê²°ì„ ê²°ì •í–ˆìŠµë‹ˆë‹¤.")
        else:
            parts.append(f"{company}ëŠ” ìê¸°ì£¼ì‹ ì·¨ë“ ì‹ íƒê³„ì•½ì„ ì²´ê²°í–ˆìŠµë‹ˆë‹¤.")
        
        # ê³„ì•½ê¸ˆì•¡
        if contract_amount:
            parts.append(f"ê³„ì•½ê¸ˆì•¡ì€ {contract_amount}ì…ë‹ˆë‹¤.")
        
        # ê³„ì•½ê¸°ê°„
        if start_date and end_date:
            parts.append(f"ê³„ì•½ê¸°ê°„ì€ {start_date}ë¶€í„° {end_date}ê¹Œì§€ì…ë‹ˆë‹¤.")
        elif start_date:
            parts.append(f"ê³„ì•½ ì‹œì‘ì¼ì€ {start_date}ì…ë‹ˆë‹¤.")
        
        # ëª©ì 
        if purpose:
            parts.append(f"ì·¨ë“ ëª©ì ì€ '{purpose}'ì…ë‹ˆë‹¤.")
        
        # ì¦ê¶Œì‚¬
        if broker:
            parts.append(f"ê³„ì•½ì²´ê²°ê¸°ê´€ì€ {broker}ì…ë‹ˆë‹¤.")
        
        # ë³´ìœ í˜„í™©
        if shares_before or shares_ratio:
            holding_info = []
            if shares_before:
                holding_info.append(f"{shares_before}")
            if shares_ratio:
                holding_info.append(f"ë¹„ìœ¨ {shares_ratio}")
            parts.append(f"ê³„ì•½ ì „ ìê¸°ì£¼ì‹ ë³´ìœ í˜„í™©ì€ {', '.join(holding_info)}ì…ë‹ˆë‹¤.")
        
        return " ".join(parts)
    
    def _generate_credit_rating_sentence(self, data: Dict, metadata: Dict) -> str:
        """ì‹ ìš©í‰ê°€ ìì—°ì–´ ë¬¸ì¥ ìƒì„±"""
        parts = []
        
        # íšŒì‚¬ëª…
        company = metadata.get('corp_name', 'íšŒì‚¬')
        
        # í‰ê°€ì¼
        eval_date = data.get('í‰ê°€ì¼', '')
        if eval_date:
            eval_date = self._normalize_dates_in_text(eval_date)
            parts.append(f"{eval_date}ì—")
        
        # ì‹ ìš©í‰ê°€ê¸°ê´€
        agency = data.get('ì‹ ìš©í‰ê°€ê¸°ê´€', '')
        if agency:
            parts.append(f"{agency}ë¡œë¶€í„°")
        
        # ì‹ ìš©ë“±ê¸‰
        rating = data.get('ì‹ ìš©ë“±ê¸‰', '')
        if rating:
            parts.append(f"{rating} ë“±ê¸‰ì„")
        
        # í‰ê°€ëª©ì 
        purpose = data.get('í‰ê°€ëª©ì ', '')
        if purpose:
            parts.append(f"{purpose} ëª©ì ìœ¼ë¡œ")
        
        # í‰ê°€êµ¬ë¶„
        eval_type = data.get('í‰ê°€êµ¬ë¶„', '')
        if eval_type:
            parts.append(f"({eval_type})")
        
        if parts:
            return f"{company}ëŠ” {' '.join(parts)} ë°›ì•˜ìŠµë‹ˆë‹¤."
        
        return ""
    
    def _generate_financial_sentence(self, data: Dict, metadata: Dict) -> str:
        """ì¬ë¬´ ë°ì´í„° ìì—°ì–´ ë¬¸ì¥ ìƒì„±"""
        parts = []

        # ê³¼ëª©ëª… ì°¾ê¸°
        item_name = None
        for key in ['ê³¼ëª©', 'ê³¼ ëª©', 'í•­ëª©', 'êµ¬ë¶„']:
            if key in data and data[key] and data[key] != '-':
                item_name = data[key]
                break

        if not item_name:
            # ì²« ë²ˆì§¸ ê°’ì´ ìˆëŠ” í‚¤ë¥¼ ê³¼ëª©ëª…ìœ¼ë¡œ
            for key, value in data.items():
                if value and value != '-' and not any(x in key for x in ['ê¸°ë§', 'ê¸°ì´ˆ', 'ë…„', 'ì£¼ì„', 'ì£¼ ì„']):
                    item_name = value
                    break

        if item_name:
            parts.append(f"{item_name}")

        # ì£¼ì„ ì •ë³´
        footnote = None
        for key in ['ì£¼ì„', 'ì£¼ ì„']:
            if key in data and data[key] and data[key] != '-':
                footnote = data[key]
                break

        # ì—°ë„ë³„/ê¸°ê°„ë³„ ê¸ˆì•¡
        amounts = []
        for key, value in data.items():
            # ê³¼ëª©ëª…, ì£¼ì„ì€ ê±´ë„ˆëœ€
            if key in ['ê³¼ëª©', 'ê³¼ ëª©', 'í•­ëª©', 'êµ¬ë¶„', 'ì£¼ì„', 'ì£¼ ì„']:
                continue

            if not value or value == '-' or not value.replace(',', '').replace('.', '').isdigit():
                continue

            # ê¸°ë§/ê¸°ì´ˆ íŒ¨í„´
            period_label = ""
            if 'ê¸°ë§' in key or 'ê¸°ì´ˆ' in key:
                # "ì œ 27(ë‹¹) ê¸°ë§" -> "ì œ27ê¸° ë§"
                period_match = re.search(r'ì œ\s*(\d+)', key)
                if period_match:
                    period_num = period_match.group(1)
                    if 'ë‹¹' in key:
                        period_label = f"ì œ{period_num}ê¸°(ë‹¹ê¸°)"
                    elif 'ì „' in key:
                        period_label = f"ì œ{period_num}ê¸°(ì „ê¸°)"
                    else:
                        period_label = f"ì œ{period_num}ê¸°"

                    if 'ê¸°ë§' in key:
                        period_label += " ë§"
                    elif 'ê¸°ì´ˆ' in key:
                        period_label += " ì´ˆ"

            # ì—°ë„ íŒ¨í„´
            elif 'ë…„' in key or re.match(r'\d{4}', key):
                year = re.search(r'\d{4}', key)
                if year:
                    period_label = f"{year.group(0)}ë…„"

            # ê¸ˆì•¡ ë³€í™˜
            amount_text = self._format_financial_amount(value)

            if period_label:
                amounts.append(f"{period_label} {amount_text}")

        # ë¬¸ì¥ ì¡°í•©
        if amounts:
            if parts:
                result = f"{parts[0]}ì€(ëŠ”) {', '.join(amounts)}ì…ë‹ˆë‹¤"
            else:
                result = f"{', '.join(amounts)}"

            # ì£¼ì„ ì¶”ê°€
            if footnote:
                result += f" (ì£¼ì„ {footnote})"

            return result

        return ""
    
    def _generate_stock_sentence(self, data: Dict, metadata: Dict) -> str:
        """ì£¼ì‹ ì •ë³´ ìì—°ì–´ ë¬¸ì¥ ìƒì„±"""
        parts = []
        company = metadata.get('corp_name', 'íšŒì‚¬')
        
        # ì£¼ì‹ ì¢…ë¥˜
        stock_type = None
        for key in ['êµ¬ ë¶„', 'êµ¬ë¶„', 'ì£¼ì‹ì¢…ë¥˜']:
            if key in data:
                stock_type = data[key]
                break
        
        if stock_type:
            parts.append(f"{company}ì˜ {stock_type}ì€(ëŠ”)")
        
        # ì£¼ì‹ìˆ˜
        shares = data.get('ì£¼ì‹ìˆ˜', data.get('ë°œí–‰ì£¼ì‹ìˆ˜', ''))
        if shares:
            shares_formatted = self._format_number_with_unit(shares, 'ì£¼')
            parts.append(f"{shares_formatted}ì´ë©°")
        
        # ê¸ˆì•¡
        amount = data.get('ê¸ˆì•¡', data.get('ë°œí–‰ê¸ˆì•¡', ''))
        if amount:
            amount_formatted = self._format_financial_amount(amount)
            parts.append(f"ê¸ˆì•¡ì€ {amount_formatted}ì…ë‹ˆë‹¤")
        
        return " ".join(parts) if parts else ""
    
    def _generate_dividend_sentence(self, data: Dict, metadata: Dict) -> str:
        """ë°°ë‹¹ ì •ë³´ ìì—°ì–´ ë¬¸ì¥ ìƒì„±"""
        parts = []
        company = metadata.get('corp_name', 'íšŒì‚¬')
        
        # ê²°ì‚°ê¸°
        fiscal_year = data.get('ê²°ì‚°ê¸°', data.get('ì‚¬ì—…ì—°ë„', ''))
        if fiscal_year:
            parts.append(f"{company}ëŠ” {fiscal_year} ê²°ì‚°ê¸°ì—")
        
        # ì£¼ë‹¹ë°°ë‹¹ê¸ˆ
        dividend = data.get('ì£¼ë‹¹ë°°ë‹¹ê¸ˆ', data.get('ë°°ë‹¹ê¸ˆ', ''))
        if dividend:
            dividend_formatted = self._format_number_with_unit(dividend, 'ì›')
            parts.append(f"ì£¼ë‹¹ {dividend_formatted}ì„")
        
        # ë°°ë‹¹ë¥ 
        dividend_rate = data.get('ë°°ë‹¹ë¥ ', data.get('ë°°ë‹¹ìˆ˜ìµë¥ ', ''))
        if dividend_rate:
            parts.append(f"ë°°ë‹¹ë¥  {dividend_rate}%ë¡œ")
        
        if parts:
            parts.append("ì§€ê¸‰í–ˆìŠµë‹ˆë‹¤")
        
        return " ".join(parts) if len(parts) > 1 else ""
    
    def _generate_executive_sentence(self, data: Dict, metadata: Dict) -> str:
        """ì„ì› ì •ë³´ ìì—°ì–´ ë¬¸ì¥ ìƒì„±"""
        parts = []

        # ì„±ëª…
        name = data.get('ì„±ëª…', data.get('ì´ë¦„', ''))
        if name:
            parts.append(f"{name}ì€(ëŠ”)")

        # ì§ìœ„
        position = data.get('ì§ìœ„', data.get('ì§ì±…', ''))
        if position:
            parts.append(f"{position}ìœ¼ë¡œ")

        # ì·¨ì„ì¼
        appointment_date = data.get('ì·¨ì„ì¼', data.get('ì„ ì„ì¼', ''))
        if appointment_date:
            date_formatted = self._normalize_dates_in_text(appointment_date)
            parts.append(f"{date_formatted}ì— ì·¨ì„í–ˆìŠµë‹ˆë‹¤")

        return " ".join(parts) if len(parts) > 1 else ""

    def _generate_fiscal_period_sentence(self, data: Dict, metadata: Dict) -> str:
        """ì‚¬ì—…ì—°ë„ ì •ë³´ ìì—°ì–´ ë¬¸ì¥ ìƒì„±"""
        company = metadata.get('corp_name', 'íšŒì‚¬')

        # ë°ì´í„° ì¶”ì¶œ
        fiscal_year = None
        start_date = None
        end_date = None

        for key, value in data.items():
            if not value or value == '-':
                continue

            # ì‚¬ì—…ì—°ë„ íŒ¨í„´
            if 'ì‚¬ì—…ì—°ë„' in key and value not in ['ë¶€í„°', 'ê¹Œì§€', 'ì‚¬ì—…ì—°ë„']:
                fiscal_year = value

            # ì¼€ì´ìŠ¤ 1: í‚¤ì™€ ê°’ ëª¨ë‘ ë‚ ì§œì¸ ê²½ìš° (ì˜ˆ: "2024ë…„ 01ì›” 01ì¼": "2024ë…„ 09ì›” 30ì¼")
            if 'ë…„' in key and 'ì›”' in key and 'ì¼' in key and 'ë…„' in value and 'ì›”' in value:
                start_date = self._normalize_dates_in_text(key)
                end_date = self._normalize_dates_in_text(value)

            # ì¼€ì´ìŠ¤ 2: ê°’ì´ "ê¹Œì§€"/"ë¶€í„°"ì´ê³  í‚¤ì— ë‚ ì§œê°€ ìˆëŠ” ê²½ìš°
            elif value == 'ê¹Œì§€' and 'ë…„' in key and 'ì›”' in key:
                end_date = self._normalize_dates_in_text(key)
            elif value == 'ë¶€í„°' and 'ë…„' in key and 'ì›”' in key:
                start_date = self._normalize_dates_in_text(key)

            # ì¼€ì´ìŠ¤ 3: í‚¤ê°€ "ë¶€í„°"/"ê¹Œì§€"ì´ê³  ê°’ì— ë‚ ì§œê°€ ìˆëŠ” ê²½ìš°
            elif ('ë¶€í„°' in key or 'ì‹œì‘' in key) and 'ë…„' in value:
                start_date = self._normalize_dates_in_text(value)
            elif ('ê¹Œì§€' in key or 'ì¢…ë£Œ' in key or 'ë§Œë£Œ' in key) and 'ë…„' in value:
                end_date = self._normalize_dates_in_text(value)

        # ë¬¸ì¥ ìƒì„±
        if start_date and end_date:
            year = start_date[:4] if start_date else ''
            return f"{company}ì˜ {year}ë…„ë„ ì‚¬ì—…ì—°ë„ëŠ” {start_date}ë¶€í„° {end_date}ê¹Œì§€ì…ë‹ˆë‹¤."
        elif fiscal_year:
            return f"{company}ì˜ ì‚¬ì—…ì—°ë„ëŠ” {fiscal_year}ì…ë‹ˆë‹¤."

        return ""

    def _generate_company_classification_sentence(self, data: Dict, metadata: Dict) -> str:
        """ì¤‘ì†Œ/ì¤‘ê²¬ê¸°ì—… ë¶„ë¥˜ ì •ë³´ ìì—°ì–´ ë¬¸ì¥ ìƒì„±"""
        company = metadata.get('corp_name', 'íšŒì‚¬')

        classifications = []

        # ë°ì´í„° ë¶„ì„ - í‚¤ì™€ ê°’ ëª¨ë‘ì—ì„œ ê¸°ì—… ìœ í˜• ì°¾ê¸°
        for key, value in data.items():
            if not value or value == '-':
                continue

            key_clean = key.strip()
            value_clean = value.strip()

            # í‚¤ ë˜ëŠ” ê°’ì—ì„œ ê¸°ì—… ìœ í˜• ê°ì§€
            enterprise_type = None
            status = None

            # ê°’ì—ì„œ ê¸°ì—… ìœ í˜• ì°¾ê¸° (ì˜ëª»ëœ íŒŒì‹± ëŒ€ì‘)
            if 'ì¤‘ì†Œê¸°ì—…' in value_clean:
                enterprise_type = 'ì¤‘ì†Œê¸°ì—…'
            elif 'ì¤‘ê²¬ê¸°ì—…' in value_clean:
                enterprise_type = 'ì¤‘ê²¬ê¸°ì—…'
            elif 'ë²¤ì²˜ê¸°ì—…' in value_clean:
                enterprise_type = 'ë²¤ì²˜ê¸°ì—…'

            # í‚¤ì—ì„œë„ ì°¾ê¸°
            if not enterprise_type:
                if 'ì¤‘ì†Œê¸°ì—…' in key_clean:
                    enterprise_type = 'ì¤‘ì†Œê¸°ì—…'
                elif 'ì¤‘ê²¬ê¸°ì—…' in key_clean:
                    enterprise_type = 'ì¤‘ê²¬ê¸°ì—…'
                elif 'ë²¤ì²˜ê¸°ì—…' in key_clean:
                    enterprise_type = 'ë²¤ì²˜ê¸°ì—…'

            # í•´ë‹¹/ë¯¸í•´ë‹¹ íŒë‹¨ (í‚¤ ë˜ëŠ” ê°’ì—ì„œ)
            if 'í•´ë‹¹' in value_clean:
                if 'ë¯¸í•´ë‹¹' in value_clean:
                    status = False
                else:
                    status = True
            elif 'í•´ë‹¹' in key_clean:
                if 'ë¯¸í•´ë‹¹' in key_clean:
                    status = False
                else:
                    status = True
            elif 'ë¯¸í•´ë‹¹' in value_clean or 'ë¯¸í•´ë‹¹' in key_clean:
                status = False

            if enterprise_type and status is not None:
                classifications.append((enterprise_type, status))

        # ì¤‘ë³µ ì œê±°
        classifications = list(dict.fromkeys(classifications))

        # ë¬¸ì¥ ìƒì„±
        if not classifications:
            return ""

        parts = []
        positive_classifications = [name for name, is_positive in classifications if is_positive]
        negative_classifications = [name for name, is_positive in classifications if not is_positive]

        if positive_classifications:
            parts.append(f"{company}ëŠ” {', '.join(positive_classifications)}ì— í•´ë‹¹í•©ë‹ˆë‹¤")

        if negative_classifications:
            if parts:
                parts.append(f"{', '.join(negative_classifications)}ì—ëŠ” í•´ë‹¹í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            else:
                parts.append(f"{company}ëŠ” {', '.join(negative_classifications)}ì— í•´ë‹¹í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

        return ". ".join(parts) + "." if parts else ""
    
    def _format_financial_amount(self, value: str) -> str:
        """ê¸ˆì•¡ì„ ì–µì›/ë§Œì› ë‹¨ìœ„ë¡œ í¬ë§·íŒ…"""
        try:
            num = int(str(value).replace(',', '').replace(' ', ''))
            if abs(num) >= 100_000_000:
                eok = num / 100_000_000
                return f"{eok:,.1f}ì–µì›" if eok != int(eok) else f"{int(eok):,}ì–µì›"
            elif abs(num) >= 10_000:
                man = num / 10_000
                return f"{man:,.1f}ë§Œì›" if man != int(man) else f"{int(man):,}ë§Œì›"
            else:
                return f"{num:,}ì›"
        except (ValueError, TypeError):
            return str(value)
    
    def _format_number_with_unit(self, value: str, unit: str) -> str:
        """ìˆ«ìì— ë‹¨ìœ„ ì¶”ê°€"""
        try:
            num = int(str(value).replace(',', '').replace(' ', ''))
            return f"{num:,}{unit}"
        except (ValueError, TypeError):
            return f"{value}{unit}"
    
    def _reduce_repetition(self, text: str) -> str:
        """ê³¼ë„í•œ ë°˜ë³µ ì¶•ì†Œ ë° ìì—°ì–´ ê°œì„ """

        # 1. ë™ì¼í•œ í‚¤-ê°’ ë°˜ë³µ ì œê±°
        # "ì¤‘ì†Œê¸°ì—… í•´ë‹¹ ì—¬ë¶€: ì¤‘ê²¬ê¸°ì—… í•´ë‹¹ ì—¬ë¶€, ì¤‘ì†Œê¸°ì—… í•´ë‹¹ ì—¬ë¶€: ì¤‘ê²¬ê¸°ì—… í•´ë‹¹ ì—¬ë¶€"
        # â†’ "ì¤‘ì†Œê¸°ì—… í•´ë‹¹ ì—¬ë¶€: ì¤‘ê²¬ê¸°ì—… í•´ë‹¹ ì—¬ë¶€"
        parts = text.split(', ')
        seen = set()
        unique_parts = []
        for part in parts:
            part_clean = part.strip()
            if part_clean and part_clean not in seen:
                unique_parts.append(part_clean)
                seen.add(part_clean)
        text = ', '.join(unique_parts)

        # 2. "í‚¤: í‚¤" íŒ¨í„´ ì œê±° (ë™ì¼í•œ í‚¤ì™€ ê°’)
        # "ì‚¬ì—…ì—°ë„: ì‚¬ì—…ì—°ë„" â†’ ""
        text = re.sub(r'([^,:]+):\s*\1(?=,|$)', '', text)

        # 3. "ì€(ëŠ”)" ì œê±°
        text = re.sub(r'ì€\(ëŠ”\)', '', text)

        # 4. ë¹ˆ í•­ëª© ì •ë¦¬ (": ," ë˜ëŠ” ì‹œì‘/ëì˜ ì½¤ë§ˆ)
        text = re.sub(r':\s*,', ',', text)
        text = re.sub(r',\s*,', ',', text)
        text = re.sub(r'^,\s*|\s*,$', '', text)

        # 5. ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
        text = re.sub(r'\s{2,}', ' ', text)

        # 6. ì½¤ë§ˆ ë’¤ ê³µë°± í†µì¼
        text = re.sub(r',\s*', ', ', text)

        # 7. ì½œë¡  ë’¤ ê³µë°± í†µì¼
        text = re.sub(r':\s+', ': ', text)

        return text.strip()
    
    def _improve_financial_text(self, text: str, data: Dict) -> str:
        """ì¬ë¬´ ë°ì´í„° ìì—°ì–´ ê°œì„  - ì¼ê´€ëœ ë‹¨ìœ„ ì¶”ê°€"""
        
        # 1. ë¨¼ì € í¼ì„¼íŠ¸ ì²˜ë¦¬ (ì†Œìˆ˜ì ì´ ìˆëŠ” ì‘ì€ ìˆ«ì)
        # 0.XX í˜•íƒœ â†’ XX%
        text = re.sub(
            r'\b0\.(\d{1,2})\b',
            lambda m: f"{int(m.group(1))}%" if m.group(1)[0] != '0' else f"{float(m.group(0))*100:.1f}%",
            text
        )
        
        # 2. í° ìˆ«ìì— ë‹¨ìœ„ ì¶”ê°€ (ì–µì›)
        def add_currency_unit(match):
            num_str = match.group(0).replace(',', '')
            try:
                num = int(num_str)
                
                # 1ì–µ ì´ìƒ â†’ ì–µì›
                if abs(num) >= 100_000_000:
                    eok = num / 100_000_000
                    if eok == int(eok):
                        return f"{int(eok):,}ì–µì›"
                    else:
                        return f"{eok:,.1f}ì–µì›"
                
                # 1ë§Œ ì´ìƒ 1ì–µ ë¯¸ë§Œ â†’ ë§Œì› (ì„ íƒì )
                elif abs(num) >= 10_000:
                    man = num / 10_000
                    if man == int(man):
                        return f"{int(man):,}ë§Œì›"
                    else:
                        return f"{man:,.1f}ë§Œì›"
                
                # ê·¸ ì™¸ â†’ ì›
                else:
                    return f"{num:,}ì›"
                    
            except (ValueError, AttributeError):
                return match.group(0)
        
        # 8ìë¦¬ ì´ìƒ ìˆ«ì (ì´ë¯¸ ë‹¨ìœ„ ì—†ëŠ” ê²½ìš°ë§Œ)
        text = re.sub(r'\b(\d{8,})(?![ì–µë§Œì›%ì£¼])', add_currency_unit, text)
        
        # ì½¤ë§ˆê°€ ìˆëŠ” ìˆ«ì (ì´ë¯¸ ë‹¨ìœ„ ì—†ëŠ” ê²½ìš°ë§Œ)
        text = re.sub(r'\b(\d{1,3}(?:,\d{3})+)(?![ì–µë§Œì›%ì£¼])', add_currency_unit, text)
        
        # 4ìë¦¬ ì´ìƒ ìˆ«ì (ë‹¨ìœ„ ì—†ëŠ” ê²½ìš°)
        text = re.sub(r'\b(\d{4,7})(?![ì–µë§Œì›%ì£¼,])', add_currency_unit, text)
        
        return text
    
    def _improve_stock_text(self, text: str, data: Dict) -> str:
        """ì£¼ì‹ ë°ì´í„° ìì—°ì–´ ê°œì„  - ì¼ê´€ëœ ë‹¨ìœ„ ì¶”ê°€"""
        
        # 1. ë¹„ìœ¨ ì²˜ë¦¬ ë¨¼ì € (í¼ì„¼íŠ¸)
        # 0.XX í˜•íƒœ â†’ XX%
        text = re.sub(
            r'\b0\.(\d{1,2})\b',
            lambda m: f"{int(m.group(1))}%" if m.group(1)[0] != '0' else f"{float(m.group(0))*100:.1f}%",
            text
        )
        
        # "ë¹„ìœ¨", "ìœ¨" í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìˆ«ìì— % ì¶”ê°€
        if 'ë¹„ìœ¨' in text or 'ìœ¨' in text or 'ì§€ë¶„' in text:
            text = re.sub(r'\b(\d+)(?!%|ì£¼|,)', r'\1%', text)
            text = re.sub(r'\b(\d+\.\d+)(?!%)', r'\1%', text)
        
        # 2. "ì£¼" ë‹¨ìœ„ ì¶”ê°€ (ì´ë¯¸ ë‹¨ìœ„ê°€ ì—†ëŠ” ê²½ìš°ë§Œ)
        # ì½¤ë§ˆê°€ ìˆëŠ” ìˆ«ì
        text = re.sub(r'\b(\d{1,3}(?:,\d{3})+)(?![ì–µë§Œì›%ì£¼])', r'\1ì£¼', text)
        
        # 4ìë¦¬ ì´ìƒ ìˆ«ì (ë‹¨ìœ„ ì—†ëŠ” ê²½ìš°)
        text = re.sub(r'\b(\d{4,})(?![ì–µë§Œì›%ì£¼,])', r'\1ì£¼', text)
        
        return text
    
    def _improve_text_content(self, text: str, metadata: Dict, section_path: str = "") -> str:
        """í…ìŠ¤íŠ¸ ì½˜í…ì¸  ê°œì„  - ê°€ë…ì„± í–¥ìƒ ë° ìŠ¤ë§ˆíŠ¸ ë¶„í• """

        # 1. ë‚ ì§œ ì •ê·œí™”
        text = self._normalize_dates_in_text(text)

        # 2. ìˆ«ìì— ë‹¨ìœ„ ì¶”ê°€ (ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜)
        text = self._add_units_to_numbers(text, section_path)

        # 3. ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        # "íšŒ ì‚¬ ëª…" â†’ "íšŒì‚¬ëª…"
        text = re.sub(r'(\S)\s+(\S)(?=\s*:)', r'\1\2', text)

        # 4. ì½œë¡  ì•ë’¤ ê³µë°± ì •ë¦¬
        # "íšŒì‚¬ëª… :" â†’ "íšŒì‚¬ëª…:"
        text = re.sub(r'\s*:\s*', ': ', text)

        # 5. ê´„í˜¸ ì•ë’¤ ê³µë°± ì •ë¦¬
        # "íšŒì‚¬ëª… ( 123 )" â†’ "íšŒì‚¬ëª…(123)"
        text = re.sub(r'\s*\(\s*', '(', text)
        text = re.sub(r'\s*\)\s*', ') ', text)

        # 6. ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì •ë¦¬
        text = re.sub(r'\n{3,}', '\n\n', text)

        # 7. ê³¼ë„í•œ ê³µë°± ì •ë¦¬
        text = re.sub(r' {2,}', ' ', text)

        return text
    
    def _add_units_to_numbers(self, text: str, section_path: str = "") -> str:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ìˆ«ì ë‹¨ìœ„ ì¶”ê°€"""
        
        # ì´ë¯¸ ë‹¨ìœ„ê°€ ìˆëŠ”ì§€ ì²´í¬
        has_unit_pattern = r'(?:[ì–µë§Œì²œë°±ì‹­]|ì›|ì£¼|%|ê±´|ê°œ|ëª…|ë…„|ì›”|ì¼)'
        
        # 1. ì¬ë¬´/ê¸ˆì•¡ ê´€ë ¨
        if any(keyword in text for keyword in ['ë§¤ì¶œ', 'ìì‚°', 'ë¶€ì±„', 'ìë³¸', 'ê¸ˆì•¡', 'ê°€ê²©', 'ì›']):
            # 8ìë¦¬ ì´ìƒ â†’ ì–µì›
            text = re.sub(
                r'\b(\d{8,})(?!' + has_unit_pattern + ')',
                lambda m: f"{int(m.group(1))/100_000_000:,.0f}ì–µì›",
                text
            )
            # ì½¤ë§ˆ ìˆ«ì â†’ ì ì ˆí•œ ë‹¨ìœ„
            text = re.sub(
                r'\b(\d{1,3}(?:,\d{3})+)(?!' + has_unit_pattern + ')',
                lambda m: self._format_currency(m.group(1)),
                text
            )
        
        # 2. ì£¼ì‹ ê´€ë ¨
        elif any(keyword in text for keyword in ['ì£¼ì‹', 'ì£¼ìˆ˜', 'ë³´í†µì£¼', 'ìš°ì„ ì£¼']):
            text = re.sub(
                r'\b(\d{1,3}(?:,\d{3})+)(?!' + has_unit_pattern + ')',
                r'\1ì£¼',
                text
            )
            text = re.sub(r'\b(\d{4,})(?!' + has_unit_pattern + ')', r'\1ì£¼', text)
        
        # 3. ë¹„ìœ¨ ê´€ë ¨
        elif any(keyword in text for keyword in ['ë¹„ìœ¨', 'ìœ¨', 'ì§€ë¶„', 'ì ìœ ']):
            # 0.XX â†’ XX%
            text = re.sub(r'\b0\.(\d+)\b', lambda m: f"{float(m.group(0))*100:.1f}%", text)
        
        return text
    
    def _format_currency(self, num_str: str) -> str:
        """ê¸ˆì•¡ í¬ë§·íŒ…"""
        try:
            num = int(num_str.replace(',', ''))
            if num >= 100_000_000:
                eok = num / 100_000_000
                return f"{eok:,.0f}ì–µì›" if eok == int(eok) else f"{eok:,.1f}ì–µì›"
            elif num >= 10_000:
                return f"{num//10_000:,}ë§Œì›"
            else:
                return f"{num:,}ì›"
        except:
            return num_str
    
    def _normalize_dates_in_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ë‚´ ë‚ ì§œ ì •ê·œí™”"""
        
        # 1. "YYYYë…„ MMì›” DDì¼" â†’ "YYYY-MM-DD"
        def korean_date_to_iso(match):
            year, month, day = match.groups()
            return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
        
        text = re.sub(
            r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼',
            korean_date_to_iso,
            text
        )
        
        # 2. "YYYY.MM.DD" â†’ "YYYY-MM-DD"
        text = re.sub(
            r'(\d{4})\.(\d{2})\.(\d{2})',
            r'\1-\2-\3',
            text
        )
        
        # 3. ê¸°ìˆ˜ í‘œí˜„ ì •ê·œí™” "ì œ 54 ê¸°" â†’ "ì œ54ê¸°"
        text = re.sub(r'ì œ\s*(\d+)\s*ê¸°', r'ì œ\1ê¸°', text)
        
        return text
    
    def _normalize_whitespace(self, text: str) -> str:
        """ê³µë°± ì •ê·œí™”"""
        
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        text = re.sub(r' {2,}', ' ', text)
        
        # ì¤„ë°”ê¿ˆ ì •ë¦¬
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        return text
    
    def _normalize_structured_data(self, data: Dict) -> Dict:
        """êµ¬ì¡°í™” ë°ì´í„° ì •ê·œí™”"""
        
        normalized = {}
        
        for key, value in data.items():
            # í‚¤ ì •ë¦¬
            clean_key = self._clean_markdown(key.strip())
            
            # ê°’ ì •ë¦¬
            if isinstance(value, str):
                clean_value = self._clean_markdown(value.strip())
                
                # ë‚ ì§œ ì •ê·œí™”
                clean_value = self._normalize_date_value(clean_value)
                
                # ìˆ«ì ì •ê·œí™” (ë‹¨ìœ„ ì •ë³´ ì¶”ê°€)
                clean_value = self._normalize_number_value(clean_value, clean_key)
                
                normalized[clean_key] = clean_value
            else:
                normalized[clean_key] = value
        
        return normalized
    
    def _normalize_date_value(self, value: str) -> str:
        """ë‚ ì§œ ê°’ ì •ê·œí™”"""
        
        # "YYYYë…„ MMì›” DDì¼" í˜•ì‹
        match = re.match(r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼', value)
        if match:
            year, month, day = match.groups()
            return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
        
        # "YYYY.MM.DD" í˜•ì‹
        match = re.match(r'(\d{4})\.(\d{2})\.(\d{2})', value)
        if match:
            return '-'.join(match.groups())
        
        return value
    
    def _normalize_number_value(self, value: str, key: str) -> str:
        """ìˆ«ì ê°’ ì •ê·œí™” (ë‹¨ìœ„ ì¶”ê°€)"""
        
        # ì´ë¯¸ ë‹¨ìœ„ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ
        if any(unit in value for unit in ['ì›', 'ì£¼', 'ì–µ', '%', 'ê±´']):
            return value
        
        # ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ í° ìˆ«ì
        if re.match(r'^[\d,]+$', value.replace(',', '')):
            num_str = value.replace(',', '')
            try:
                num = int(num_str)
                
                # ë¬¸ë§¥ì—ì„œ ë‹¨ìœ„ ì¶”ë¡  (ì£¼ì„ í•„ë“œ ì œì™¸)
                if ('ì£¼ì‹' in key or 'ì£¼' in key) and 'ì£¼ì„' not in key and 'ì£¼ ì„' not in key:
                    return f"{value}ì£¼"
                elif 'ìì‚°' in key or 'ë¶€ì±„' in key or 'ìë³¸' in key or 'ë§¤ì¶œ' in key or 'ê¸ˆì•¡' in key:
                    if abs(num) >= self.config.currency_unit_threshold:
                        eok = num / 100_000_000
                        if eok == int(eok):
                            return f"{int(eok):,}ì–µì›"
                        else:
                            return f"{eok:,.1f}ì–µì›"
                    return f"{value}ì›"
                
            except:
                pass
        
        return value


def process_jsonl_file(input_file: str, output_file: str):
    """
    Step 2: JSONL íŒŒì¼ ì •ê·œí™”
    
    ì…ë ¥: step1_structuredì˜ JSONL íŒŒì¼
    ì¶œë ¥: step2_normalizedì˜ JSONL íŒŒì¼
    """
    
    normalizer = DataNormalizer()
    
    processed_count = 0
    error_count = 0
    
    with open(input_file, 'r', encoding='utf-8') as infile, \
         open(output_file, 'w', encoding='utf-8') as outfile:

        for line_no, line in enumerate(infile, 1):
            try:
                chunk = json.loads(line)
                result = normalizer.normalize_chunk(chunk)

                # normalize_chunkì€ ë‹¨ì¼ chunk ë˜ëŠ” chunk ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
                if isinstance(result, list):
                    # ë¶„í• ëœ ê²½ìš° ëª¨ë“  chunk ì €ì¥
                    for normalized_chunk in result:
                        outfile.write(json.dumps(normalized_chunk, ensure_ascii=False) + '\n')
                        processed_count += 1
                else:
                    # ë‹¨ì¼ chunk ì €ì¥
                    outfile.write(json.dumps(result, ensure_ascii=False) + '\n')
                    processed_count += 1
            except Exception as e:
                print(f"âš ï¸  Line {line_no} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                error_count += 1
                continue
    
    print(f"âœ… {processed_count}ê°œ ì²­í¬ ì •ê·œí™” ì™„ë£Œ")
    if error_count > 0:
        print(f"âš ï¸  {error_count}ê°œ ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨")


def process_directory(input_dir: str, output_dir: str):
    """
    Step 2: ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  JSONL íŒŒì¼ ì •ê·œí™”
    
    ì…ë ¥: data/transform/structured/
    ì¶œë ¥: data/transform/normalized/
    """
    from pathlib import Path
    
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    jsonl_files = list(input_path.glob("*_chunks.jsonl"))
    
    if not jsonl_files:
        print("âŒ JSONL íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("=" * 80)
    print("Transform Pipeline - Step 2: ë°ì´í„° ì •ê·œí™” ë° í’ˆì§ˆ ê°œì„ ")
    print("=" * 80)
    print(f"ğŸ“ ì…ë ¥: {input_path}")
    print(f"ğŸ“ ì¶œë ¥: {output_path}")
    print(f"ğŸ“„ ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(jsonl_files)}ê°œ")
    print(f"\nì²˜ë¦¬ ë‚´ìš©: ë§ˆí¬ë‹¤ìš´ ì œê±°, ìˆ«ì ë‹¨ìœ„ ë³€í™˜, ë‚ ì§œ ì •ê·œí™”, í’ˆì§ˆ ê°œì„ ")
    print(f"ë‹¤ìŒ ë‹¨ê³„: chunker.pyë¡œ ìŠ¤ë§ˆíŠ¸ ì²­í‚¹ ìˆ˜í–‰")
    print("=" * 80)
    print()
    
    for i, input_file in enumerate(jsonl_files, 1):
        print(f"[{i}/{len(jsonl_files)}] ì²˜ë¦¬ ì¤‘: {input_file.name}")
        output_file = output_path / input_file.name
        process_jsonl_file(str(input_file), str(output_file))
        print(f"  ğŸ’¾ ì €ì¥: {output_file.name}")
        print()
    
    print("=" * 80)
    print("Step 2 ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    import sys
    from pathlib import Path
    
    # ë””ë ‰í† ë¦¬ ëª¨ë“œ (ê¶Œì¥)
    if len(sys.argv) == 1:
        # ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
        script_dir = Path(__file__).parent
        data_dir = script_dir.parent.parent.parent / "data"
        input_dir = data_dir / "transform" / "structured"
        output_dir = data_dir / "transform" / "normalized"
        
        process_directory(str(input_dir), str(output_dir))
    
    # ë‹¨ì¼ íŒŒì¼ ëª¨ë“œ
    elif len(sys.argv) == 3:
        input_file = sys.argv[1]
        output_file = sys.argv[2]
        process_jsonl_file(input_file, output_file)
    
    else:
        print("ì‚¬ìš©ë²•:")
        print("  1. ë””ë ‰í† ë¦¬ ëª¨ë“œ (ê¶Œì¥): python data_normalizer.py")
        print("  2. ë‹¨ì¼ íŒŒì¼ ëª¨ë“œ:      python data_normalizer.py <input.jsonl> <output.jsonl>")
        sys.exit(1)