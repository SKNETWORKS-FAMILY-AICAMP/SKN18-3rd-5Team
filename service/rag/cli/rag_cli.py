#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
RAG ì‹œìŠ¤í…œ í†µí•© CLI

Usage:
  rag-eval all              # 5ê°œ ëª¨ë¸ ì „ì²´ í‰ê°€
  rag-eval model --model E5  # íŠ¹ì • ëª¨ë¸ í‰ê°€
  rag-eval reranking        # ë¦¬ë­í‚¹ íš¨ê³¼ ë¹„êµ
"""

import os
import sys
import logging
import argparse
from pathlib import Path
from typing import List, Optional, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(project_root))

from ..models.config import EmbeddingModelType, get_model_config
from ..core.evaluator import RAGEvaluator
from ..core.embedder import MultiModelEmbedder
from ..rag_system import RAGSystem
from ..retrieval.reranker import KeywordReranker, SemanticReranker, CombinedReranker
from ..augmentation.formatters import (
    PromptFormatter,
    MarkdownFormatter,
    JSONFormatter,
    PolicyFormatter,
    EnhancedPromptFormatter
)
from ..generation.generator import OllamaGenerator, GenerationConfig
from backend.services.db.common.db_utils import test_connection

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def get_db_config() -> dict:
    """ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
    return {
        'host': os.getenv('PG_HOST', 'localhost'),
        'port': os.getenv('PG_PORT', '5432'),
        'database': os.getenv('PG_DB', 'rey'),
        'user': os.getenv('PG_USER', 'postgres'),
        'password': os.getenv('PG_PASSWORD', 'post1234')
    }


def list_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸")
    print("="*80)
    print(f"{'ëª¨ë¸ íƒ€ì…':<30} {'ì´ë¦„':<40} {'ì°¨ì›':>6}")
    print("-"*80)

    for model_type in EmbeddingModelType:
        config = get_model_config(model_type)
        print(f"{model_type.name:<30} {config.display_name:<40} {config.dimension:>6}")

    print("="*80)
    print("\nì‚¬ìš© ë°©ë²•:")
    print("  rag-eval model --model E5")
    print("  rag-eval model --model KAKAOBANK_DEBERTA")
    print()


def evaluate_single_model(
    model_type: EmbeddingModelType,
    db_config: dict,
    top_k: int = 5,
    use_reranking: bool = False,
    save_results: bool = True,
    save_search_results: bool = False
) -> bool:
    """ë‹¨ì¼ ëª¨ë¸ í‰ê°€"""
    try:
        logger.info(f"=== {model_type.value} ëª¨ë¸ í‰ê°€ ì‹œì‘ ===")

        evaluator = RAGEvaluator(db_config)
        result = evaluator.evaluate_model(
            model_type=model_type,
            top_k=top_k,
            use_reranking=use_reranking,
            save_search_results=save_search_results
        )

        if result.get('status') == 'failed':
            logger.error(f"í‰ê°€ ì‹¤íŒ¨: {result.get('error')}")
            return False

        # ê²°ê³¼ ì €ì¥
        if save_results:
            output_path = evaluator.save_results({'evaluation': result})
            print(f"\nâœ… í‰ê°€ ê²°ê³¼ ì €ì¥: {output_path}")

        return True

    except Exception as e:
        logger.exception(f"ëª¨ë¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def evaluate_all_models(
    db_config: dict,
    top_k: int = 5,
    compare_reranking: bool = False,
    save_results: bool = True,
    save_search_results: bool = False
) -> bool:
    """ì „ì²´ ëª¨ë¸ í‰ê°€"""
    try:
        logger.info("=== 5ê°œ ëª¨ë¸ ì „ì²´ í‰ê°€ ì‹œì‘ ===")

        # ëª¨ë“  ëª¨ë¸
        models = list(EmbeddingModelType)

        evaluator = RAGEvaluator(db_config)
        results = evaluator.evaluate_all_models(
            models=models,
            top_k=top_k,
            compare_reranking=compare_reranking,
            save_search_results=save_search_results
        )

        # ìš”ì•½ ì¶œë ¥
        print(results['summary'])

        # ìƒì„¸ ë¹„êµ ì¶œë ¥
        print_comparison_table(results)

        # ë¦¬ë­í‚¹ ë¹„êµ (ì˜µì…˜)
        if compare_reranking and results.get('reranking_comparison'):
            print_reranking_comparison(results['reranking_comparison'])

        # ê²°ê³¼ ì €ì¥
        if save_results:
            output_path = evaluator.save_results(results)
            print(f"\nâœ… ì „ì²´ í‰ê°€ ê²°ê³¼ ì €ì¥: {output_path}")

        return True

    except Exception as e:
        logger.exception(f"ì „ì²´ ëª¨ë¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def print_comparison_table(results: dict):
    """ë¹„êµ ê²°ê³¼ë¥¼ í‘œë¡œ ì¶œë ¥"""
    print("\n" + "="*120)
    print("ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    print("="*120)

    comparisons = results.get('comparison', {}).get('comparisons', {})

    if not comparisons:
        print("ë¹„êµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í—¤ë”
    print(f"{'ëª¨ë¸ëª…':<40} {'í‰ê·  Latency':>15} {'P95 Latency':>15} {'ìœ ì‚¬ë„':>10} {'Recall@5':>12} {'MRR':>10}")
    print("-"*120)

    # ê° ëª¨ë¸ ì •ë³´
    for model_name in comparisons.get('accuracy', {}).keys():
        latency = comparisons.get('latency', {}).get(model_name, {})
        accuracy = comparisons.get('accuracy', {}).get(model_name, 0)
        recall = comparisons.get('recall', {}).get(model_name, 0)
        mrr = comparisons.get('mrr', {}).get(model_name, 0)

        avg_lat = latency.get('avg', 0)
        p95_lat = latency.get('p95', 0)

        print(
            f"{model_name:<40} "
            f"{avg_lat:>13.2f}ms "
            f"{p95_lat:>13.2f}ms "
            f"{accuracy:>10.4f} "
            f"{recall:>12.4f} "
            f"{mrr:>10.4f}"
        )

    print("="*120)


def print_reranking_comparison(reranking_effects: dict):
    """ë¦¬ë­í‚¹ íš¨ê³¼ ë¹„êµ ì¶œë ¥"""
    print("\n" + "="*100)
    print("ë¦¬ë­í‚¹ íš¨ê³¼ ë¹„êµ")
    print("="*100)
    print(f"{'ëª¨ë¸ëª…':<30} {'ìœ ì‚¬ë„ ê°œì„ ':>15} {'Latency ì˜¤ë²„í—¤ë“œ':>20} {'Recall@5 ê°œì„ ':>18} {'NDCG@5 ê°œì„ ':>18}")
    print("-"*100)

    for model_name, improvements in reranking_effects.items():
        sim_imp = improvements.get('similarity', 0)
        lat_over = improvements.get('latency_overhead', 0)
        recall_imp = improvements.get('recall_at_5', 0)
        ndcg_imp = improvements.get('ndcg_at_5', 0)

        print(
            f"{model_name:<30} "
            f"{sim_imp:>13.2f}% "
            f"{lat_over:>18.2f}ms "
            f"{recall_imp:>18.4f} "
            f"{ndcg_imp:>18.4f}"
        )

    print("="*100)


def embed_all_models(
    data_file: str,
    db_config: dict
) -> bool:
    """5ê°œ ëª¨ë¸ë¡œ ë°ì´í„° ì„ë² ë”©"""
    try:
        logger.info("=== 5ê°œ ëª¨ë¸ ì„ë² ë”© ìƒì„± ì‹œì‘ ===")

        if not Path(data_file).exists():
            logger.error(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_file}")
            return False

        embedder = MultiModelEmbedder(data_file, db_config, skip_chunking=True)
        results = embedder.embed_all_models()

        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print(embedder.get_summary())

        # ì„±ê³µí•œ ëª¨ë¸ í™•ì¸
        successful = [k for k, v in results.items() if v.get("status") == "success"]

        if successful:
            logger.info(f"âœ… {len(successful)}ê°œ ëª¨ë¸ ì„ë² ë”© ì™„ë£Œ")
            return True
        else:
            logger.error("âŒ ëª¨ë“  ëª¨ë¸ ì„ë² ë”© ì‹¤íŒ¨")
            return False

    except Exception as e:
        logger.exception(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def get_model_type_from_name(model_name: str) -> EmbeddingModelType:
    """ëª¨ë¸ ì´ë¦„ì„ EmbeddingModelTypeìœ¼ë¡œ ë³€í™˜"""
    mapping = {
        "E5": EmbeddingModelType.MULTILINGUAL_E5_SMALL,
        "KAKAO": EmbeddingModelType.KAKAOBANK_DEBERTA,
        "QWEN": EmbeddingModelType.QWEN_EMBEDDING,
        "GEMMA": EmbeddingModelType.EMBEDDING_GEMMA
    }
    return mapping.get(model_name.upper(), EmbeddingModelType.MULTILINGUAL_E5_SMALL)


def get_formatter_from_name(format_name: str):
    """í¬ë§· ì´ë¦„ì„ í¬ë§·í„° ê°ì²´ë¡œ ë³€í™˜"""
    formatters = {
        "prompt": PromptFormatter(),
        "markdown": MarkdownFormatter(),
        "json": JSONFormatter(),
        "policy": PolicyFormatter(),
        "enhanced": EnhancedPromptFormatter()
    }
    return formatters.get(format_name.lower(), PromptFormatter())


def save_augment_result_to_markdown(
    query: str,
    response: Any,
    model: str,
    output_dir: str = "results"
) -> str:
    """ì¦ê°• ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥"""
    import os
    from datetime import datetime
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # íŒŒì¼ëª… ìƒì„± (ì¿¼ë¦¬ + íƒ€ì„ìŠ¤íƒ¬í”„)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_query = "".join(c for c in query if c.isalnum() or c in (' ', '-', '_')).rstrip()
    safe_query = safe_query.replace(' ', '_')[:50]  # ìµœëŒ€ 50ì
    filename = f"augment_{safe_query}_{model}_{timestamp}.md"
    filepath = os.path.join(output_dir, filename)
    
    # ë§ˆí¬ë‹¤ìš´ ë‚´ìš© ìƒì„±
    markdown_content = f"""# RAG ì¦ê°• ê²°ê³¼

## ì¿¼ë¦¬
{query}

## ëª¨ë¸ ì •ë³´
- ëª¨ë¸: {model}
- ìƒì„± ì‹œê°„: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ê²€ìƒ‰ëœ ë¬¸ì„œ ({len(response.retrieved_documents)}ê°œ)

"""
    
    # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ ì¶”ê°€
    for i, doc in enumerate(response.retrieved_documents, 1):
        similarity = doc.get('similarity', 0)
        content = doc.get('content', '')
        metadata = doc.get('metadata', {})
        
        markdown_content += f"""### ë¬¸ì„œ {i} (ìœ ì‚¬ë„: {similarity:.3f})

**ë‚´ìš©:**
{content}

**ë©”íƒ€ë°ì´í„°:**
- ì¶œì²˜: {metadata.get('source', 'N/A')}
- ì›ë³¸ ID: {metadata.get('original_id', 'N/A')}

---

"""
    
    # ì¦ê°•ëœ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    markdown_content += f"""## ì¦ê°•ëœ ì»¨í…ìŠ¤íŠ¸

**í† í° ìˆ˜:** {response.augmented_context.token_count}
**ì²˜ë¦¬ ì‹œê°„:** {response.augmented_context.processing_time_ms:.2f}ms

**ì»¨í…ìŠ¤íŠ¸:**
```
{response.augmented_context.context_text}
```

## ë©”íƒ€ë°ì´í„°

- ì´ ë¬¸ì„œ ìˆ˜: {response.augmented_context.metadata.get('total_documents', 0)}
- ì„ íƒëœ ë¬¸ì„œ ìˆ˜: {response.augmented_context.metadata.get('selected_documents', 0)}
- ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {response.augmented_context.metadata.get('context_length', 0)}
- í‰ê·  ìœ ì‚¬ë„: {response.augmented_context.metadata.get('avg_similarity', 0):.3f}
"""
    
    # íŒŒì¼ ì €ì¥
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(markdown_content)
    
    return filepath


def run_search_command(args, db_config: dict) -> bool:
    """ê²€ìƒ‰ ëª…ë ¹ì–´ ì‹¤í–‰"""
    try:
        model_type = get_model_type_from_name(args.model)
        formatter = get_formatter_from_name(args.format)
        
        # Reranker ì„¤ì •
        reranker = None
        if args.reranking:
            reranker = KeywordReranker()
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag_system = RAGSystem(
            model_type=model_type,
            db_config=db_config,
            reranker=reranker,
            formatter=formatter
        )
        
        # ê²€ìƒ‰ ì‹¤í–‰
        print(f"\nğŸ” ê²€ìƒ‰ ì¤‘... (ëª¨ë¸: {args.model}, Top-K: {args.top_k})")
        search_results = rag_system.search_only(
            query=args.query,
            top_k=args.top_k,
            use_reranker=args.reranking
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ({len(search_results)}ê°œ ë¬¸ì„œ)")
        print("=" * 80)
        
        for i, doc in enumerate(search_results, 1):
            print(f"\n[ë¬¸ì„œ {i}] (ìœ ì‚¬ë„: {doc.get('similarity', 0):.3f})")
            print(f"ë‚´ìš©: {doc.get('content', '')[:200]}...")
            if doc.get('metadata'):
                print(f"ë©”íƒ€ë°ì´í„°: {doc.get('metadata')}")
        
        return True
        
    except Exception as e:
        logger.exception(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def run_augment_command(args, db_config: dict) -> bool:
    """ì¦ê°• ëª…ë ¹ì–´ ì‹¤í–‰"""
    try:
        model_type = get_model_type_from_name(args.model)
        formatter = get_formatter_from_name(args.format)
        
        # Reranker ì„¤ì •
        reranker = None
        if args.reranking:
            reranker = KeywordReranker()
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag_system = RAGSystem(
            model_type=model_type,
            db_config=db_config,
            reranker=reranker,
            formatter=formatter
        )
        
        # ê²€ìƒ‰ ë° ì¦ê°• ì‹¤í–‰
        print(f"\nğŸ” ê²€ìƒ‰ ë° ì¦ê°• ì¤‘... (ëª¨ë¸: {args.model}, í¬ë§·: {args.format})")
        response = rag_system.retrieve_and_augment(
            query=args.query,
            top_k=args.top_k,
            use_reranker=args.reranking,
            context_type=args.context_type
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ({len(response.retrieved_documents)}ê°œ ë¬¸ì„œ)")
        print("=" * 80)
        
        for i, doc in enumerate(response.retrieved_documents, 1):
            print(f"\n[ë¬¸ì„œ {i}] (ìœ ì‚¬ë„: {doc.get('similarity', 0):.3f})")
            print(f"ë‚´ìš©: {doc.get('content', '')[:200]}...")
        
        print(f"\nğŸ¤– ì¦ê°•ëœ ì»¨í…ìŠ¤íŠ¸ (í† í° ìˆ˜: {response.augmented_context.token_count})")
        print("=" * 80)
        print(response.augmented_context.context_text)
        
        # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥
        if args.save:
            filepath = save_augment_result_to_markdown(
                query=args.query,
                response=response,
                model=args.model,
                output_dir=args.output_dir
            )
            print(f"\nğŸ’¾ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")
        
        return True
        
    except Exception as e:
        logger.exception(f"ì¦ê°• ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def run_rag_eval_command(args, db_config: dict) -> bool:
    """RAG ì‹œìŠ¤í…œ í‰ê°€ ëª…ë ¹ì–´ ì‹¤í–‰"""
    try:
        model_type = get_model_type_from_name(args.model)

        # Reranker ì„¤ì •
        reranker = None
        if args.reranking:
            reranker = KeywordReranker()

        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag_system = RAGSystem(
            model_type=model_type,
            db_config=db_config,
            reranker=reranker
        )

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ë¡œë“œ
        test_queries = [
            "ì£¼ê±°ë³µì§€ì‚¬ì—…ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì²­ë…„ ì£¼ê±° ì§€ì› ì •ì±…ì€ ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?",
            "ì„ëŒ€ì£¼íƒ ì‹ ì²­ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ì£¼ê±°ê¸‰ì—¬ ì‹ ì²­ ìê²©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ê³µê³µì„ëŒ€ì£¼íƒê³¼ ë¯¼ê°„ì„ëŒ€ì£¼íƒì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        ]

        print(f"\nğŸ§ª RAG ì‹œìŠ¤í…œ í‰ê°€ ì¤‘... (ëª¨ë¸: {args.model}, ì¿¼ë¦¬: {len(test_queries)}ê°œ)")

        # í‰ê°€ ì‹¤í–‰
        eval_results = rag_system.evaluate_retrieval(
            queries=test_queries,
            top_k=args.top_k,
            use_reranker=args.reranking
        )

        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š RAG ì‹œìŠ¤í…œ í‰ê°€ ê²°ê³¼")
        print("=" * 80)
        print(f"ì´ ì¿¼ë¦¬ ìˆ˜: {eval_results['total_queries']}")
        print(f"ì„±ê³µí•œ ì¿¼ë¦¬: {eval_results['successful_queries']}")
        print(f"ì‹¤íŒ¨í•œ ì¿¼ë¦¬: {eval_results['failed_queries']}")
        print(f"í‰ê·  ê²€ìƒ‰ ì‹œê°„: {eval_results['avg_time_ms']:.2f}ms")
        print(f"ì¿¼ë¦¬ë‹¹ í‰ê·  ë¬¸ì„œ ìˆ˜: {eval_results['avg_documents_per_query']:.1f}")
        print(f"í‰ê·  ìœ ì‚¬ë„: {eval_results['avg_similarity']:.3f}")

        # ê°œë³„ ì¿¼ë¦¬ ê²°ê³¼
        print(f"\nğŸ“‹ ê°œë³„ ì¿¼ë¦¬ ê²°ê³¼")
        print("-" * 80)
        for i, query_result in enumerate(eval_results['queries'], 1):
            if query_result['success']:
                print(f"{i}. {query_result['query'][:50]}...")
                print(f"   ë¬¸ì„œ ìˆ˜: {query_result['documents_found']}, ìœ ì‚¬ë„: {query_result['avg_similarity']:.3f}, ì‹œê°„: {query_result['time_ms']:.1f}ms")
            else:
                print(f"{i}. {query_result['query'][:50]}... (ì‹¤íŒ¨: {query_result['error']})")

        return True

    except Exception as e:
        logger.exception(f"RAG í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def run_generate_command(args, db_config: dict) -> bool:
    """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ê²€ìƒ‰ + ì¦ê°• + ìƒì„±)"""
    try:
        model_type = get_model_type_from_name(args.model)
        formatter = get_formatter_from_name(args.format)

        # Reranker ì„¤ì •
        reranker = None
        if args.reranking:
            reranker = KeywordReranker()

        # LLM Generator ì´ˆê¸°í™”
        llm_generator = OllamaGenerator(
            base_url=args.ollama_url,
            default_model=args.llm_model
        )

        # Ollama ì„œë²„ ìƒíƒœ í™•ì¸
        if not llm_generator.check_health():
            logger.error(f"Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.ollama_url}")
            print(f"\nâŒ Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤.")
            print(f"ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Ollamaë¥¼ ì‹œì‘í•˜ì„¸ìš”: ollama serve")
            return False

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
        available_models = llm_generator.list_models()
        if args.llm_model not in available_models:
            logger.warning(f"ëª¨ë¸ '{args.llm_model}'ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print(f"\nâš ï¸  ëª¨ë¸ '{args.llm_model}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì„ ì„¤ì¹˜í•˜ì„¸ìš”: ollama pull {args.llm_model}")
            print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {', '.join(available_models)}")
            return False

        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag_system = RAGSystem(
            model_type=model_type,
            db_config=db_config,
            reranker=reranker,
            formatter=formatter,
            llm_generator=llm_generator,
            enable_generation=True
        )

        # ìƒì„± ì„¤ì •
        gen_config = GenerationConfig(
            model=args.llm_model,
            temperature=args.temperature,
            max_tokens=args.max_tokens
        )

        # ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        print(f"\nğŸ” RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
        print(f"  - ì„ë² ë”© ëª¨ë¸: {args.model}")
        print(f"  - LLM ëª¨ë¸: {args.llm_model}")
        print(f"  - ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {args.top_k}")
        print(f"  - ë¦¬ë­í‚¹: {'ì‚¬ìš©' if args.reranking else 'ë¯¸ì‚¬ìš©'}")

        response = rag_system.generate_answer(
            query=args.query,
            top_k=args.top_k,
            use_reranker=args.reranking,
            context_type=args.context_type,
            generation_config=gen_config
        )

        # ê²°ê³¼ ì¶œë ¥
        print(f"\n" + "="*80)
        print(f"ğŸ“ ì§ˆë¬¸: {args.query}")
        print("="*80)

        print(f"\nğŸ¤– AI ë‹µë³€:")
        print("-"*80)
        print(response.generated_answer.answer)
        print("-"*80)

        print(f"\nğŸ“Š ìƒì„± ì •ë³´:")
        print(f"  - ëª¨ë¸: {response.generated_answer.model}")
        print(f"  - ìƒì„± ì‹œê°„: {response.generated_answer.generation_time_ms:.2f}ms")
        print(f"  - í† í° ìˆ˜: {response.generated_answer.tokens_used}")

        print(f"\nğŸ“š ì°¸ê³  ë¬¸ì„œ ({len(response.retrieved_documents)}ê°œ):")
        for i, doc in enumerate(response.retrieved_documents, 1):
            similarity = doc.get('similarity', 0)
            source = doc.get('metadata', {}).get('source', 'N/A')
            print(f"  {i}. [{similarity:.3f}] {source}")

        # ê²°ê³¼ ì €ì¥
        if args.save:
            from datetime import datetime
            import json

            os.makedirs(args.output_dir, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_query = "".join(c for c in args.query if c.isalnum() or c in (' ', '-', '_')).rstrip()
            safe_query = safe_query.replace(' ', '_')[:50]
            filename = f"rag_result_{safe_query}_{args.llm_model.replace(':', '_')}_{timestamp}.json"
            filepath = os.path.join(args.output_dir, filename)

            result_data = {
                "query": args.query,
                "answer": response.generated_answer.answer,
                "model_info": {
                    "embedding_model": args.model,
                    "llm_model": response.generated_answer.model,
                    "generation_time_ms": response.generated_answer.generation_time_ms,
                    "tokens_used": response.generated_answer.tokens_used
                },
                "retrieved_documents": [
                    {
                        "similarity": doc.get('similarity'),
                        "content": doc.get('content'),
                        "metadata": doc.get('metadata')
                    }
                    for doc in response.retrieved_documents
                ],
                "context": response.augmented_context.context_text,
                "timestamp": timestamp
            }

            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)

            print(f"\nğŸ’¾ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")

        return True

    except Exception as e:
        logger.exception(f"RAG ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def main():
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ.setdefault("PG_USER", "postgres")
    os.environ.setdefault("PG_PASSWORD", "post1234")
    os.environ.setdefault("PG_HOST", "localhost")
    os.environ.setdefault("PG_PORT", "5432")
    os.environ.setdefault("PG_DB", "rey")

    parser = argparse.ArgumentParser(
        description="rag: RAG ì‹œìŠ¤í…œ ë„êµ¬ (ê²€ìƒ‰, ì¦ê°•, í‰ê°€)"
    )
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")

    subparsers = parser.add_subparsers(dest="command", help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´")

    # ëª¨ë¸ ëª©ë¡
    p_list = subparsers.add_parser("list", help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡")

    # ë‹¨ì¼ ëª¨ë¸ í‰ê°€
    p_model = subparsers.add_parser("model", help="ë‹¨ì¼ ëª¨ë¸ í‰ê°€")
    p_model.add_argument(
        "--model",
        type=str,
        required=True,
        choices=[m.name for m in EmbeddingModelType],
        help="í‰ê°€í•  ëª¨ë¸"
    )
    p_model.add_argument("--top-k", type=int, default=5, help="ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 5)")
    p_model.add_argument("--reranking", action="store_true", help="ë¦¬ë­í‚¹ ì‚¬ìš©")
    p_model.add_argument("--no-save", action="store_true", help="ê²°ê³¼ ì €ì¥ ì•ˆ í•¨")
    p_model.add_argument("--save-search-results", action="store_true", help="ê²€ìƒ‰ ê²°ê³¼ë„ í•¨ê»˜ ì €ì¥ (íŒŒì¼ í¬ê¸° ì¦ê°€)")

    # ì „ì²´ ëª¨ë¸ í‰ê°€
    p_all = subparsers.add_parser("all", help="ì „ì²´ ëª¨ë¸ í‰ê°€")
    p_all.add_argument("--top-k", type=int, default=5, help="ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 5)")
    p_all.add_argument("--no-save", action="store_true", help="ê²°ê³¼ ì €ì¥ ì•ˆ í•¨")
    p_all.add_argument("--save-search-results", action="store_true", help="ê²€ìƒ‰ ê²°ê³¼ë„ í•¨ê»˜ ì €ì¥ (íŒŒì¼ í¬ê¸° ì¦ê°€)")

    # ë¦¬ë­í‚¹ ë¹„êµ
    p_rerank = subparsers.add_parser("reranking", help="ë¦¬ë­í‚¹ ì „í›„ ì„±ëŠ¥ ë¹„êµ")
    p_rerank.add_argument("--top-k", type=int, default=5, help="ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 5)")
    p_rerank.add_argument("--no-save", action="store_true", help="ê²°ê³¼ ì €ì¥ ì•ˆ í•¨")
    p_rerank.add_argument("--save-search-results", action="store_true", help="ê²€ìƒ‰ ê²°ê³¼ë„ í•¨ê»˜ ì €ì¥ (íŒŒì¼ í¬ê¸° ì¦ê°€)")

    # RAG ì‹œìŠ¤í…œ ê²€ìƒ‰
    p_search = subparsers.add_parser("search", help="RAG ì‹œìŠ¤í…œìœ¼ë¡œ ê²€ìƒ‰")
    p_search.add_argument("query", type=str, help="ê²€ìƒ‰ ì¿¼ë¦¬")
    p_search.add_argument("--model", type=str, default="E5", choices=["E5", "KAKAO", "QWEN", "GEMMA"], help="ì‚¬ìš©í•  ëª¨ë¸")
    p_search.add_argument("--top-k", type=int, default=5, help="ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜")
    p_search.add_argument("--reranking", action="store_true", help="ë¦¬ë­í‚¹ ì‚¬ìš©")
    p_search.add_argument("--format", type=str, default="prompt", choices=["prompt", "markdown", "json", "policy", "enhanced"], help="ì¶œë ¥ í¬ë§·")
    
    # RAG ì‹œìŠ¤í…œ ì¦ê°•
    p_augment = subparsers.add_parser("augment", help="ê²€ìƒ‰ ê²°ê³¼ ì¦ê°•")
    p_augment.add_argument("query", type=str, help="ê²€ìƒ‰ ì¿¼ë¦¬")
    p_augment.add_argument("--model", type=str, default="E5", choices=["E5", "KAKAO", "QWEN", "GEMMA"], help="ì‚¬ìš©í•  ëª¨ë¸")
    p_augment.add_argument("--top-k", type=int, default=5, help="ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜")
    p_augment.add_argument("--reranking", action="store_true", help="ë¦¬ë­í‚¹ ì‚¬ìš©")
    p_augment.add_argument("--format", type=str, default="prompt", choices=["prompt", "markdown", "json", "policy", "enhanced"], help="ì¶œë ¥ í¬ë§·")
    p_augment.add_argument("--context-type", type=str, default="general", choices=["general", "qa", "summarization"], help="ì»¨í…ìŠ¤íŠ¸ íƒ€ì…")
    p_augment.add_argument("--save", action="store_true", help="ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥")
    p_augment.add_argument("--output-dir", type=str, default="results", help="ì €ì¥í•  ë””ë ‰í† ë¦¬")
    
    # RAG ì‹œìŠ¤í…œ í‰ê°€
    p_rag_eval = subparsers.add_parser("rag-eval", help="RAG ì‹œìŠ¤í…œ ì „ì²´ í‰ê°€")
    p_rag_eval.add_argument("--model", type=str, default="E5", choices=["E5", "KAKAO", "QWEN", "GEMMA"], help="ì‚¬ìš©í•  ëª¨ë¸")
    p_rag_eval.add_argument("--top-k", type=int, default=5, help="ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜")
    p_rag_eval.add_argument("--reranking", action="store_true", help="ë¦¬ë­í‚¹ ì‚¬ìš©")
    p_rag_eval.add_argument("--no-save", action="store_true", help="ê²°ê³¼ ì €ì¥ ì•ˆ í•¨")

    # RAG ìƒì„± (ì „ì²´ íŒŒì´í”„ë¼ì¸)
    p_generate = subparsers.add_parser("generate", help="RAG ì „ì²´ íŒŒì´í”„ë¼ì¸ (ê²€ìƒ‰ + ì¦ê°• + ìƒì„±)")
    p_generate.add_argument("query", type=str, help="ì§ˆë¬¸")
    p_generate.add_argument("--model", type=str, default="E5", choices=["E5", "KAKAO", "QWEN", "GEMMA"], help="ì„ë² ë”© ëª¨ë¸")
    p_generate.add_argument("--llm-model", type=str, default="gemma2:2b", help="LLM ëª¨ë¸ (ì˜ˆ: gemma2:2b)")
    p_generate.add_argument("--top-k", type=int, default=5, help="ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜")
    p_generate.add_argument("--reranking", action="store_true", help="ë¦¬ë­í‚¹ ì‚¬ìš©")
    p_generate.add_argument("--format", type=str, default="enhanced", choices=["prompt", "markdown", "json", "policy", "enhanced"], help="ì»¨í…ìŠ¤íŠ¸ í¬ë§·")
    p_generate.add_argument("--context-type", type=str, default="general", choices=["general", "qa", "summarization"], help="ì»¨í…ìŠ¤íŠ¸ íƒ€ì…")
    p_generate.add_argument("--temperature", type=float, default=0.7, help="ìƒì„± ì˜¨ë„ (0.0-1.0)")
    p_generate.add_argument("--max-tokens", type=int, default=1000, help="ìµœëŒ€ í† í° ìˆ˜")
    p_generate.add_argument("--ollama-url", type=str, default="http://localhost:11434", help="Ollama API URL")
    p_generate.add_argument("--save", action="store_true", help="ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥")
    p_generate.add_argument("--output-dir", type=str, default="results", help="ì €ì¥í•  ë””ë ‰í† ë¦¬")

    # ì„ë² ë”© ìƒì„±
    p_embed = subparsers.add_parser("embed", help="4ê°œ ëª¨ë¸ë¡œ ë°ì´í„° ì„ë² ë”©")
    p_embed.add_argument(
        "--data-file",
        type=str,
        required=True,
        help="ì„ë² ë”©í•  JSON ë°ì´í„° íŒŒì¼"
    )

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # DB ì—°ê²° í…ŒìŠ¤íŠ¸
    if args.command not in ['list']:
        logger.info("DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        if not test_connection():
            logger.error("DB ì—°ê²° ì‹¤íŒ¨")
            sys.exit(1)
        logger.info("DB ì—°ê²° ì„±ê³µ")

    db_config = get_db_config()

    success = False

    # ëª…ë ¹ì–´ ì‹¤í–‰
    if args.command == "list":
        list_models()
        success = True

    elif args.command == "model":
        model_type = EmbeddingModelType[args.model]
        success = evaluate_single_model(
            model_type=model_type,
            db_config=db_config,
            top_k=args.top_k,
            use_reranking=args.reranking,
            save_results=not args.no_save,
            save_search_results=args.save_search_results
        )

    elif args.command == "all":
        success = evaluate_all_models(
            db_config=db_config,
            top_k=args.top_k,
            compare_reranking=False,
            save_results=not args.no_save,
            save_search_results=args.save_search_results
        )

    elif args.command == "reranking":
        success = evaluate_all_models(
            db_config=db_config,
            top_k=args.top_k,
            compare_reranking=True,
            save_results=not args.no_save,
            save_search_results=args.save_search_results
        )
    
    elif args.command == "search":
        success = run_search_command(args, db_config)
    
    elif args.command == "augment":
        success = run_augment_command(args, db_config)
    
    elif args.command == "rag-eval":
        success = run_rag_eval_command(args, db_config)

    elif args.command == "generate":
        success = run_generate_command(args, db_config)

    elif args.command == "embed":
        success = embed_all_models(
            data_file=args.data_file,
            db_config=db_config
        )

    if success:
        logger.info(f"{args.command} ëª…ë ¹ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    else:
        logger.error(f"{args.command} ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨")
        sys.exit(1)


if __name__ == "__main__":
    main()
