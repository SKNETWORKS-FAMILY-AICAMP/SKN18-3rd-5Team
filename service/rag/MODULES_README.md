# RAG ëª¨ë“ˆ ìƒì„¸ ê°€ì´ë“œ

**ê° ëª¨ë“ˆë³„ í•µì‹¬ ê¸°ëŠ¥ê³¼ í•¨ìˆ˜ ì„¤ëª…**

---

## ğŸ“ ëª¨ë“ˆ êµ¬ì¡°

```
service/rag/
â”œâ”€â”€ retrieval/          # ê²€ìƒ‰ + ë¦¬ë­í‚¹
â”œâ”€â”€ augmentation/       # ì»¨í…ìŠ¤íŠ¸ ì¦ê°•
â”œâ”€â”€ generation/         # LLM ë‹µë³€ ìƒì„±
â”œâ”€â”€ evaluation/         # ì„±ëŠ¥ í‰ê°€
â”œâ”€â”€ models/             # ì„ë² ë”© ëª¨ë¸
â”œâ”€â”€ query/              # ì¿¼ë¦¬ ë¶„ì„
â”œâ”€â”€ vectorstore/        # ë²¡í„° DB
â””â”€â”€ cli/                # CLI ë„êµ¬
```

---

## ğŸ” 1. Retrieval (ê²€ìƒ‰)

### `retrieval/retriever.py`

**í†µí•© ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„ (ë²¡í„°/í‚¤ì›Œë“œ/í•˜ì´ë¸Œë¦¬ë“œ)**

í•˜ë‚˜ì˜ `Retriever` í´ë˜ìŠ¤ë¡œ ëª¨ë“  ê²€ìƒ‰ ë°©ë²• ì§€ì›

#### ê²€ìƒ‰ ë°©ë²•

| í•¨ìˆ˜               | ë°©ë²•           | ì„¤ëª…               |
| ------------------ | -------------- | ------------------ |
| `vector_search()`  | pgvector       | ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ |
| `keyword_search()` | PostgreSQL FTS | ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ |
| `hybrid_search()`  | ê²°í•©           | ë‘ ë°©ë²• Fusion     |

#### í•µì‹¬ í•¨ìˆ˜

```python
async def hybrid_search(
    query: str,                    # ì¿¼ë¦¬ í…ìŠ¤íŠ¸
    query_embedding: List[float],  # ì¿¼ë¦¬ ì„ë² ë”©
    config: SearchConfig,          # ê²€ìƒ‰ ì„¤ì •
    top_k: int = 10                # ë°˜í™˜ ë¬¸ì„œ ìˆ˜
) -> List[Dict]
```

#### Fusion ì•Œê³ ë¦¬ì¦˜

- **RRF (Reciprocal Rank Fusion)**: `score = Î£(1/(k+rank))`
- **Weighted Sum**: `score = w1*vec + w2*kw`
- **Max Score**: ê° ë¬¸ì„œì˜ ìµœê³  ì ìˆ˜

---

## ğŸ¯ 2. Reranker (ì¬ì •ë ¬)

### `retrieval/hybrid_reranker_combined.py`

**2ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­í‚¹**

#### ì‘ë™ ì›ë¦¬

```
Stage 1: Rule-based (ë¹ ë¥¸ í•„í„°ë§)
  â†“ top_k * 2~3ë°° ì„ íƒ
Stage 2: Cross-Encoder (ì •ë°€ í‰ê°€)
  â†“ ìµœì¢… top_k ì„ íƒ
```

#### í•µì‹¬ í´ë˜ìŠ¤

```python
class HybridReranker:
    def __init__(
        stage1_reranker=None,        # 1ë‹¨ê³„ (ê¸°ë³¸: CombinedReranker)
        use_cross_encoder=True,       # Cross-Encoder ì‚¬ìš© ì—¬ë¶€
        stage1_top_k_multiplier=3.0,  # 1ë‹¨ê³„ ë°°ìˆ˜
        cross_encoder_model="BAAI/bge-reranker-v2-m3"
    )

    def rerank(query, candidates, top_k) -> List[Dict]
```

---

## ğŸ“ 3. Augmentation (ì¦ê°•)

### `augmentation/augmenter.py`

**ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLM ì…ë ¥ìœ¼ë¡œ ë³€í™˜**

#### í•µì‹¬ í•¨ìˆ˜

```python
def augment(
    query: str,                 # ì›ë³¸ ì¿¼ë¦¬
    search_results: List[Dict], # ê²€ìƒ‰ ê²°ê³¼
    formatter: BaseFormatter    # í¬ë§·í„°
) -> AugmentedContext
```

#### ì²˜ë¦¬ ê³¼ì •

1. ì¤‘ë³µ ë¬¸ì„œ ì œê±° (deduplication)
2. í† í° ìˆ˜ ê³„ì‚° ë° ì œí•œ
3. Formatterë¡œ í˜•ì‹ ë³€í™˜
4. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (citations)

#### ì¶œë ¥

```python
class AugmentedContext:
    context_text: str           # í¬ë§·íŒ…ëœ ì»¨í…ìŠ¤íŠ¸
    token_count: int            # í† í° ìˆ˜
    documents_used: List[Dict]  # ì‚¬ìš©ëœ ë¬¸ì„œ
    citations: List[Dict]       # ì¸ìš© ì •ë³´
```

---

### `augmentation/formatters.py`

**ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹**

#### Formatter ì¢…ë¥˜

```python
class PromptFormatter:
    def format(query, documents) -> str
    # ì¶œë ¥: "ì°¸ê³  ë¬¸ì„œ:\n1. ...\n2. ..."

class MarkdownFormatter:
    def format(query, documents) -> str
    # ì¶œë ¥: "### ë¬¸ì„œ 1\n**ì œëª©**: ...\n**ë‚´ìš©**: ..."

class JSONFormatter:
    def format(query, documents) -> str
    # ì¶œë ¥: JSON ë¬¸ìì—´
```

---

## ğŸ¤– 4. Generation (ìƒì„±)

### `generation/generator.py`

**LLM ë‹µë³€ ìƒì„±**

#### í•µì‹¬ í´ë˜ìŠ¤

```python
class OllamaGenerator(LLMGenerator):
    def generate(
        query: str,                      # ì§ˆë¬¸
        context: str,                    # ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸
        config: GenerationConfig = None  # ìƒì„± ì„¤ì •
    ) -> GeneratedAnswer
```

#### ìƒì„± ì„¤ì •

```python
@dataclass
class GenerationConfig:
    model: str = "gemma3:4b"
    temperature: float = 0.7
    max_tokens: int = 1000
    top_p: float = 0.9
```

#### ì¶œë ¥

```python
@dataclass
class GeneratedAnswer:
    answer: str              # ìƒì„±ëœ ë‹µë³€
    model: str               # ì‚¬ìš©ëœ ëª¨ë¸
    tokens_used: int         # ì‚¬ìš©ëœ í† í°
    generation_time_ms: float  # ìƒì„± ì‹œê°„
```

---

## ğŸ“Š 5. Evaluation (í‰ê°€)

### `evaluation/ragas_evaluator.py`

**RAG í’ˆì§ˆ í‰ê°€ (RAGAs ë©”íŠ¸ë¦­)**

#### í‰ê°€ ë©”íŠ¸ë¦­

```python
class RAGASEvaluator:
    def evaluate_faithfulness(answer, contexts) -> float
    # ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•˜ëŠ”ê°€? (0.0~1.0)

    def evaluate_answer_relevancy(query, answer) -> float
    # ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ”ê°€? (0.0~1.0)

    def evaluate_context_precision(query, contexts) -> float
    # ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ê°€ ì •í™•í•œê°€? (0.0~1.0)

    def evaluate_context_recall(contexts, ground_truth) -> float
    # í•„ìš”í•œ ì •ë³´ë¥¼ ëª¨ë‘ ê²€ìƒ‰í–ˆëŠ”ê°€? (0.0~1.0)
```

#### í†µí•© í‰ê°€

```python
def evaluate(
    query: str,
    answer: str,
    contexts: List[str],
    ground_truth: str = None
) -> RAGEvaluation
```

#### ì¶œë ¥

```python
@dataclass
class RAGEvaluation:
    faithfulness: float          # ì¶©ì‹¤ì„±
    answer_relevancy: float      # ë‹µë³€ ê´€ë ¨ì„±
    context_precision: float     # ì»¨í…ìŠ¤íŠ¸ ì •ë°€ë„
    context_recall: float        # ì»¨í…ìŠ¤íŠ¸ ì¬í˜„ìœ¨
    average_score: float         # í‰ê·  ì ìˆ˜
```

---

### `evaluation/compare_retrieval_methods.py`

**ê²€ìƒ‰ ë°©ë²• ë¹„êµ ì‹¤í—˜**

#### í•µì‹¬ í´ë˜ìŠ¤

```python
class RetrievalComparisonExperiment:
    async def compare_methods(
        test_queries: List[Dict],  # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        top_k: int = 5,
        use_reranker: bool = True
    ) -> pd.DataFrame
```

#### ë¹„êµ ëŒ€ìƒ

- Vector Search (pgvector)
- Keyword Search (PostgreSQL FTS)
- Hybrid Search (RRF/Weighted)

#### ì¶œë ¥ ë©”íŠ¸ë¦­

- `search_time_ms`: ê²€ìƒ‰ ì‹œê°„
- `rerank_time_ms`: ë¦¬ë­í‚¹ ì‹œê°„
- `faithfulness`: ì¶©ì‹¤ì„± ì ìˆ˜
- `context_precision`: ì •ë°€ë„
- `average_score`: ì¢…í•© ì ìˆ˜

---

## ğŸ§© 6. Query (ì¿¼ë¦¬ ë¶„ì„)

### `query/temporal_parser.py`

**ì‹œê°„ í‘œí˜„ íŒŒì‹±**

#### í•µì‹¬ í•¨ìˆ˜

```python
def parse_temporal_query(query: str) -> Dict
```

#### ì…ì¶œë ¥ ì˜ˆì‹œ

```python
# ì…ë ¥: "2024ë…„ 2ë¶„ê¸° ì‹¤ì ì€?"
# ì¶œë ¥: {'year': 2024, 'quarter': 2}

# ì…ë ¥: "ì‘ë…„ 12ì›” ë§¤ì¶œì€?"
# ì¶œë ¥: {'year': 2024, 'month': 12}
```

---

## ğŸ¨ 7. Models (ì„ë² ë”© ëª¨ë¸)

### `models/encoder.py`

**ì„ë² ë”© ëª¨ë¸ í†µí•© ê´€ë¦¬**

#### í•µì‹¬ í•¨ìˆ˜

```python
def get_encoder(
    model_type: EmbeddingModelType,
    device: str = None
) -> Encoder

class Encoder:
    def encode_query(text: str) -> List[float]
    # ì¿¼ë¦¬ ì„ë² ë”© (ë‹¨ì¼)

    def encode_documents(texts: List[str]) -> List[List[float]]
    # ë¬¸ì„œ ì„ë² ë”© (ë°°ì¹˜)

    def get_dimension() -> int
    # ë²¡í„° ì°¨ì› ë°˜í™˜
```

#### ì§€ì› ëª¨ë¸

```python
class EmbeddingModelType(Enum):
    MULTILINGUAL_E5_SMALL = "intfloat/multilingual-e5-small"  # 384ì°¨ì›
    KAKAOBANK_DEBERTA = "kakaobank/kf-deberta-base"           # 768ì°¨ì›
    FINE5_FINANCE = "fine5-finance"                           # 4096ì°¨ì›
```

---

## ğŸ—„ï¸ 8. VectorStore (ë²¡í„° DB)

### `vectorstore/pgvector_store.py`

**PostgreSQL + pgvector ì¸í„°í˜ì´ìŠ¤**

#### í•µì‹¬ í•¨ìˆ˜

```python
async def insert_embeddings(
    documents: List[Dict]  # [{'chunk_id', 'embedding', 'metadata'}, ...]
) -> None

async def search_similar(
    embedding: List[float],
    top_k: int = 10,
    min_similarity: float = 0.0
) -> List[Dict]

async def create_index() -> None
# HNSW ì¸ë±ìŠ¤ ìƒì„±
```

---

## ğŸ”„ Self-RAG / Corrective RAG

### **ê°œë…**

ë‹µë³€ í’ˆì§ˆì„ ê²€ì¦í•˜ê³ , í’ˆì§ˆì´ ë‚®ìœ¼ë©´ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì¬ê²€ìƒ‰

### **êµ¬í˜„ ìœ„ì¹˜**

- **LangGraph**: `graph/nodes/grounding_check.py`
- **ë¡œì§**: ë‹µë³€ì— `[ref:]` ì—†ìœ¼ë©´ ì¬ì‹œë„

### **ì‘ë™ íë¦„**

```
1. Retrieve (Vector) â†’ ë¬¸ì„œ ê²€ìƒ‰
2. Rerank â†’ ì¬ì •ë ¬
3. Generate â†’ ë‹µë³€ ìƒì„±
4. GroundingCheck â†’ [ref:] ê²€ì¦
   â”œâ”€ ì„±ê³µ â†’ Guardrailë¡œ ì§„í–‰
   â””â”€ ì‹¤íŒ¨ â†’ Retrieveë¡œ ì¬ì‹œë„ (ìµœëŒ€ 1íšŒ)
            (ë‹¤ë¥¸ ê²€ìƒ‰ ë°©ë²• ì‚¬ìš© ê°€ëŠ¥)
```

### **í™•ì¥ ì•„ì´ë””ì–´**

```python
# graph/nodes/grounding_check.py
def run(state: QAState) -> QAState:
    ans = state.get("draft_answer", "")
    grounded = ("[ref:" in ans)

    if not grounded and state.get("retry_count", 0) < 1:
        # ì¬ê²€ìƒ‰ ì „ëµ ì„¤ì •
        if state["search_method"] == "vector":
            state["search_method"] = "keyword"  # Vector ì‹¤íŒ¨ â†’ Keyword
        elif state["search_method"] == "keyword":
            state["search_method"] = "hybrid"   # Keyword ì‹¤íŒ¨ â†’ Hybrid

        state["retry_count"] = state.get("retry_count", 0) + 1
        # Retrieve ë…¸ë“œë¡œ ëŒì•„ê° (LangGraph ì—£ì§€ ì„¤ì •)

    state["grounded"] = grounded
    return state
```

### **ì´ë¦„**

- **Self-RAG**: ìê¸° ê²€ì¦ RAG
- **Corrective RAG (CRAG)**: êµì • RAG
- **Adaptive RAG**: ì ì‘í˜• RAG

---

## ğŸ“– ì „ì²´ íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ

```python
from service.rag.retrieval.retriever import Retriever
from service.rag.retrieval.reranker import HybridReranker
from service.rag.augmentation.augmenter import DocumentAugmenter
from service.rag.augmentation.formatters import PromptFormatter
from service.rag.generation.generator import OllamaGenerator
from service.rag.evaluation.ragas_evaluator import RAGASEvaluator
from service.rag.models.config import EmbeddingModelType

# 1. í†µí•© ê²€ìƒ‰ (ë²¡í„°/í‚¤ì›Œë“œ/í•˜ì´ë¸Œë¦¬ë“œ)
retriever = Retriever(
    model_type=EmbeddingModelType.MULTILINGUAL_E5_SMALL,
    enable_temporal_filter=True,
    enable_hybrid=True  # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í™œì„±í™”
)

# ë²¡í„° ê²€ìƒ‰ (ê¸°ë³¸)
results = retriever.search(
    query="2ì°¨ì „ì§€ ì‚°ì—… ì „ë§",
    top_k=20,
    search_method="vector"
)

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ì¬ì‹œë„ ì‹œ)
results = retriever.search(
    query="2ì°¨ì „ì§€ ì‚°ì—… ì „ë§",
    top_k=20,
    search_method="hybrid"
)

# 2. í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­í‚¹
reranker = HybridReranker(
    use_cross_encoder=True,
    stage1_top_k_multiplier=3.0
)
reranked = reranker.rerank(
    query="2ì°¨ì „ì§€ ì‚°ì—… ì „ë§",
    candidates=results,
    top_k=5
)

# 3. ì»¨í…ìŠ¤íŠ¸ ì¦ê°•
augmenter = DocumentAugmenter(max_context_length=4000)
formatter = PromptFormatter()
augmented = augmenter.augment(
    query="2ì°¨ì „ì§€ ì‚°ì—… ì „ë§",
    search_results=reranked,
    formatter=formatter
)

# 4. ë‹µë³€ ìƒì„±
generator = OllamaGenerator()
answer = generator.generate(
    query="2ì°¨ì „ì§€ ì‚°ì—… ì „ë§",
    context=augmented.context_text
)

# 5. RAG í‰ê°€
evaluator = RAGASEvaluator()
evaluation = evaluator.evaluate(
    query="2ì°¨ì „ì§€ ì‚°ì—… ì „ë§",
    answer=answer.answer,
    contexts=[doc['chunk_text'] for doc in reranked]
)

print(f"ë‹µë³€: {answer.answer}")
print(f"Faithfulness: {evaluation.faithfulness:.3f}")
print(f"Overall Score: {evaluation.average_score:.3f}")
```

---

## ğŸ¯ í•µì‹¬ í•¨ìˆ˜ ì¹˜íŠ¸ì‹œíŠ¸

| ëª¨ë“ˆ                | í•¨ìˆ˜                             | ì…ë ¥                   | ì¶œë ¥                 |
| ------------------- | -------------------------------- | ---------------------- | -------------------- |
| **Retriever**       | `search(query, top_k)`           | ì¿¼ë¦¬ ë¬¸ìì—´            | ìœ ì‚¬ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸     |
| **HybridRetriever** | `hybrid_search(query, emb, cfg)` | ì¿¼ë¦¬ + ì„ë² ë”©          | í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ |
| **Reranker**        | `rerank(query, cands, k)`        | ì¿¼ë¦¬ + í›„ë³´            | ì¬ì •ë ¬ëœ ë¬¸ì„œ        |
| **HybridReranker**  | `rerank(query, cands, k)`        | ì¿¼ë¦¬ + í›„ë³´            | 2ë‹¨ê³„ ë¦¬ë­í‚¹ ê²°ê³¼    |
| **Augmenter**       | `augment(q, results, fmt)`       | ì¿¼ë¦¬ + ê²°ê³¼            | AugmentedContext     |
| **Generator**       | `generate(q, ctx)`               | ì¿¼ë¦¬ + ì»¨í…ìŠ¤íŠ¸        | GeneratedAnswer      |
| **RAGASEvaluator**  | `evaluate(q, a, ctx)`            | ì¿¼ë¦¬ + ë‹µë³€ + ì»¨í…ìŠ¤íŠ¸ | RAGEvaluation        |
| **Encoder**         | `encode_query(text)`             | í…ìŠ¤íŠ¸                 | ì„ë² ë”© ë²¡í„°          |
| **TemporalParser**  | `parse_temporal_query(q)`        | ì¿¼ë¦¬                   | ì‹œê°„ ì •ë³´ Dict       |

---

**ì‘ì„±ì¼**: 2025-01-26
**ë²„ì „**: 1.0
