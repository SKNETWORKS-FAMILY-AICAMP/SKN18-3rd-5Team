# ë°œí‘œ ìë£Œ ë©”ëª¨ README
> ì¶”í›„ ì œê±° 

--- 

## í”„ë¡œì íŠ¸ëª…
**ê³µì‹œ ë¬¸ì„œ ë° ì• ë„ë¦¬ìŠ¤íŠ¸ ë¶„ì„ ë¦¬í¬íŠ¸ ê¸°ë°˜ì˜ íˆ¬ì Q&A ì‹œìŠ¤í…œ**
- ì‚¬ìš©ìì˜ íˆ¬ì ì§€ì‹ ìˆ˜ì¤€ ì¸ì‹ ë¡œì§ìœ¼ë¡œ ì ì‘í˜• ì‹œìŠ¤í…œ (ê°œì¸í™”)

---

## [ğŸ§© ETLì˜ ì •ì˜]
**ETL**ì€ **Extract** â†’ **Transform** â†’ **Loadì˜** ì¤„ì„ë§ì´ì—ìš”.
ì¦‰, ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³ (Extract), ê°€ê³µí•˜ê³ (Transform), ì €ì¥í•˜ëŠ”(Load) ì „ì²´ ê³¼ì •ì„ ë§í•´ìš”.

âœ… í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ë©´
**ë°ì´í„°ë¥¼ ê¹¨ë—í•˜ê²Œ ì •ë¦¬í•´ì„œ ì“¸ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì˜®ê¸°ëŠ” íŒŒì´í”„ë¼ì¸**ì´ì—ìš”.

âš™ï¸ 2. ETLì˜ í”„ë¡œì„¸ìŠ¤ ìš”ì•½
| ë‹¨ê³„                | ì˜ë¯¸                                   | ì˜ˆì‹œ                           |
| ----------------- | ------------------------------------ | ---------------------------- |
| **E (Extract)**   | ì—¬ëŸ¬ ê³³(ì›¹, DB, API ë“±)ì—ì„œ ì›ë³¸ ë°ì´í„°ë¥¼ ëŒì–´ì˜¤ëŠ” ë‹¨ê³„ | APIë¡œ XML ë°ì´í„° ë‹¤ìš´ë¡œë“œ            |
| **T (Transform)** | ë¶ˆí•„ìš”í•œ ë°ì´í„°ë¥¼ ì œê±°í•˜ê³ , ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ê°€ê³µ   | XML â†’ ìì—°ì–´ ë¬¸ì„œí™” (MD + YAML ë³€í™˜) |
| **L (Load)**      | ê°€ê³µëœ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë²¡í„°DBì— ì €ì¥            | Embedding í›„ VectorDBì— ì €ì¥     |


```scss
API (XML)
 â†“
> [Extract]
 â†“
ë¬¸ì„œí™” (MD + YAML)
 â†“
> [Transform]
 â†“
ì²­í¬ ì„ë² ë”© â†’ ë²¡í„°DB
 â†“
> [Load]
 â†“
ì§ˆì˜ â†’ ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±
```

### ğŸ§  ì™œ ETLì´ ì¤‘ìš”í•œê°€?
| ì´ìœ                   | ì„¤ëª…                                                           |
| ------------------- | ------------------------------------------------------------ |
| **1ï¸âƒ£ ì •í™•ì„± í™•ë³´**      | ì›ë³¸ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì“°ë©´ ì˜¤ë¥˜ë‚˜ ì¤‘ë³µì´ ë§ì•„ìš”. ETLì€ ë°ì´í„°ë¥¼ ì •ì œ(clean)í•´ì„œ ì¼ê´€ì„±ì„ ë³´ì¥í•´ìš”. |
| **2ï¸âƒ£ íš¨ìœ¨ì„± í–¥ìƒ**      | ì‚¬ëŒì´ ì¼ì¼ì´ ë³€í™˜í•˜ëŠ” ëŒ€ì‹  ìë™í™”ëœ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì²˜ë¦¬ ì†ë„ê°€ ìˆ˜ì‹­ ë°° ë¹¨ë¼ì§‘ë‹ˆë‹¤.              |
| **3ï¸âƒ£ ë¶„ì„/AI í™œìš© ê¸°ë°˜** | LLM, ë¨¸ì‹ ëŸ¬ë‹, ëŒ€ì‹œë³´ë“œ, ë¦¬í¬íŠ¸ ë“± ëª¨ë“  ë°ì´í„° ë¶„ì„ì€ ETLì„ ê±°ì¹œ í›„ ê°€ëŠ¥í•©ë‹ˆë‹¤.           |
| **4ï¸âƒ£ ì¬ì‚¬ìš©ì„± í™•ë³´**     | ë™ì¼í•œ ETL íŒŒì´í”„ë¼ì¸ì„ ìœ ì§€í•˜ë©´, ë‚˜ì¤‘ì— ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì¶”ê°€ë¡œ ì—°ê²°í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.             |


---

## [ë¬¸ì„œí™”]
> XML â†’ ì˜ë¯¸ìˆëŠ” ìì—°ì–´ ë ˆì´ì–´(ë¬¸ì„œí™”) â†’ ì²­í¬/ì„ë² ë”©

### 1. ì™œ ë¬¸ì„œí™”ê°€ ìœ ë¦¬í•œê°€
- ì˜ë¯¸ ë‹¨ìœ„ ë³´ì¡´: XMLì€ í•„ë“œ/íƒœê·¸ ë‚˜ì—´(ë§¥ë½ ë¶€ì¡±). ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ â€œì¦ê°/ë¹„êµ/ê¸°ê°„/ì‚¬ìœ â€ë¥¼ í•¨ê»˜ ì„œìˆ í•˜ë©´ ê²€ìƒ‰ ì ì¤‘ë¥ â†‘, ë‹µë³€ í’ˆì§ˆâ†‘.
- ì¤‘ë³µÂ·ë…¸ì´ì¦ˆ ì œê±°: íƒœê·¸ëª…/ì†ì„±/ë¶ˆí•„ìš” ê³µë°± ë“± ë¶ˆìš© í† í°ì„ ì¤„ì—¬ ì„ë² ë”© íš¨ìœ¨â†‘.
- ì¶œì²˜ ì¸ìš©ì´ ì‰¬ì›€: â€œDART, ì ‘ìˆ˜ë²ˆí˜¸, í˜ì´ì§€/ì„¹ì…˜â€ì„ **ë¬¸ì¥ê³¼** í•¨ê»˜ ê°™ì´ ì €ì¥í•˜ë‹ˆ ê·¼ê±° ì œì‹œ ì •í™•.
- ì§ˆë¬¸ ì í•©ì„±: ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ë¬»ê¸° ë•Œë¬¸ì—, ì»¨í…ìŠ¤íŠ¸ë„ ìì—°ì–´ê°€ ë§ìŒ.

**ë”°ë¼ì„œ ë¬¸ì„œí™” ì—†ì´ ì›ë³¸ XML ê·¸ëŒ€ë¡œ ì„ë² ë”©í•˜ë©´**:
íƒœê·¸ê°€ ì„ì¸ í…ìŠ¤íŠ¸ê°€ ëŠ˜ì–´ì ¸ ê²€ìƒ‰ í’ˆì§ˆ ì €í•˜, ìˆ«ìë§Œ ë§ì€ ì²­í¬ëŠ” ë¬¸ë§¥ ë§¤ì¹­ ì•½í™”, ì‘ë‹µì— ê·¼ê±° ë¬¸êµ¬ê°€ ì–´ìƒ‰í•´ì§ˆ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤.


### 2. ETL - RAG
- E : Dart -> API -> XML -> ì•½ 5000ê°œ -> Google Drive / -> 1ê°œì˜ .jsonl (5000ë¼ì¸) ë¡œì»¬ì— ì €ì¥ 
- T : JSONL & XML -> ì •ê·œí™” -> ìì—°ì–´ ë¬¸ì„œí™” (yaml / md) -> ë¡œì»¬ ì €ì¥ (docs/{corp}/{year}/{reprt_code}/{rcept_no}.md) -> ì²­í¬ (1ì°¨/2ì°¨ ) + ë©”íƒ€ ë™ë´‰ -> .parquet íŒŒì¼ ìƒì„±
- L : Parquet & MD -> text ì„ë² ë”© -> pgvector -> (í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ìƒ‰ì¸) -> ë¬¸ì„œ CDN ì—…ë¡œë“œ ë³´ë¥˜ -> ì„œë¹™ (ì§ˆì˜ ë° ì‘ë‹µ)

### 3. ETL - FineTuning
- 

--- 

## [Fine-Tuning]

### 1. ëª©ì 
- ì¦ê¶Œì‚¬ ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìš”ì•½/ì½”ë©˜íŠ¸ë¥¼ ì´ìš©í•´ì„œ ë¦¬ìŠ¤í¬/ë°¸ë¥˜ì—ì´ì…˜/ê°€ì´ë˜ìŠ¤ í•´ì„ í¬í•¨í•œ "ê³µì‹œ í•´ì„ ì§€ëŠ¥" í•™ìŠµ

### 2. Llama Factory
- ì°¸ê³  : [SK Tech ë¸”ë¡œê·¸](https://devocean.sk.com/blog/techBoardDetail.do?ID=166098)
- ì •ì˜ :  
  LLaMA FactoryëŠ” Metaì˜ LLaMA ë° ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ LLM(ëŒ€í˜•ì–¸ì–´ëª¨ë¸) ê³„ì—´ ëª¨ë¸ì„ ì‰½ê²Œ íŒŒì¸íŠœë‹, í”„ë¡¬í”„íŠ¸ ë¯¸ì„¸ì¡°ì •(Instruction Tuning), ì±„íŒ…/ì›¹UI ë°°í¬ê¹Œì§€ ì§€ì›í•˜ëŠ” ì˜¬ì¸ì› ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.  
  ê¸°ì¡´ HuggingFace Transformers ê¸°ë°˜ì´ë©°, ë‹¤ì–‘í•œ ë¯¸ì„¸ì¡°ì • ë°©ë²•(LoRA, QLoRA, P-Tuning ë“±), ë°ì´í„°ì…‹ í¬ë§· ì§€ì›, Web UI(ê·¸ë¼ë””ì˜¤ ê¸°ë°˜)ë¡œ GUI í™˜ê²½ì—ì„œ ì†ì‰½ê²Œ ì»¤ìŠ¤í…€ í•™ìŠµ/í…ŒìŠ¤íŠ¸/ë°°í¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
  ì¦‰, **LLM ëª¨ë¸ íŒŒì¸íŠœë‹ê³¼ ìš´ì˜**ì„ ì½”ë“œ ëª‡ ì¤„, í˜¹ì€ í´ë¦­ë§Œìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆê²Œ ë•ëŠ” í•™ìŠµÂ·ì„œë¹™ìš© **í”„ë ˆì„ì›Œí¬**ì…ë‹ˆë‹¤.

#### [ì„¤ì¹˜]

1. runpod (ë„ì»¤ í•„ìš” ì—†ìŒ)
   - SSH ì„¤ì •
        ```bash
        $ ssh-keygen -t ed25519 -C "runpod"
        $ vi ~/.ssh/id_ed25519.pub
        ```
     - ë…¸íŠ¸ë¶ì—ì„œ ssh í‚¤ ìƒì„± í›„ ë³µì‚¬
     - runpod ë©”ë‰´ > settings > **SSH Public Keys** > ë³µì‚¬ ë¶™ì—¬ë„£ê¸°
   - ì¸ìŠ¤í„´ìŠ¤ ìŠ¤í™ ì„ íƒ(ê°€ê²© í™•ì¸) : **L4 24G**
     - ì†Œê·œëª¨ : L4 24G
     - ë¯¸ì„¸íŠœë‹: L4 24G or 4090 24G
     - ë³¸ê²© í•™ìŠµ / ëŒ€í˜• ëª¨ë¸ : A100 80GB(SXM/PCIE) ë˜ëŠ” H100
   - Disk ì„¸íŒ… : **Container (30) / Volume (200)**
     - ì†Œê·œëª¨ : Container (20~30) / Volume (50~100)
     - 8K ì»¨í…ìŠ¤íŠ¸ / ë°ì´í„°ì…‹ í¬í•¨ í•™ìŠµ : Container (40) / Volume (200~300 ì´ìƒ)
     - HuggingFace ìºì‹œ / ëª¨ë¸ ì—¬ëŸ¬ ê°œ / ê²°ê³¼ ë°±ì—… : Container (40) / Volume (300 ~ 1T)
   - Volume Mount Path: **/workspace**
   - Port ì„¤ì •: **7860** (LLaMA-Factory ê¸°ë³¸ WebUI í¬íŠ¸)
   - GPU Count : **1**
   - Encrypt Volume X / **SSH Terminal Access O** / Start Jupyter Notebook X
2. SSH ì ‘ì†
   - **ë¡œì»¬** í„°ë¯¸ë„ ì´ìš©í•  ê²½ìš° : Pods Detail > [**SSH over exposed TCP**] ì»¤ë©˜ë“œ ë³µì‚¬ í›„ ì‹¤í–‰
   - **ì›¹** í„°ë¯¸ë„ ì´ìš© : [**Enable Web Terminal**] ìŠ¤ìœ„ì¹˜ ON > Web Terminal ì ‘ì†
3. ë¼ë§ˆ íŒ©í† ë¦¬ ì„¤ì¹˜
   - ì„¤ì¹˜
        ```bash
        cd /workspace
        git clone https://github.com/hiyouga/LLaMA-Factory.git
        cd LLaMA-Factory

        # ê°€ìƒ í™˜ê²½ í™œì„±í™” (ëŸ°íŒŸ ì¬ì‹œë™ í•˜ë©´ pip install ëª©ë¡ ì‚¬ë¼ì§)
        python -m venv .venv
        source .venv/bin/activate
        python -V; which python

        pip install -r requirements.txt
        pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
        pip install --no-deps xformers
        pip install -e .[metrics,bitsandbytes,qwen]
        ```
    - ì›¹ ì ‘ì† í™•ì¸
        ```bash
        python src/webui.py --server_name 0.0.0.0 --port 7860 --share
        ```
    - ì—ëŸ¬ ë‚  ê²½ìš° (ì˜µì…˜)
        - ì›¹ ì ‘ì† ì»¤ë§¨ë“œ ì‹¤í–‰í•˜ë©´ì„œ í™•ì¸
        ```bash
        cd /workspace/LLaMA-Factory
        # ê¸°ë³¸ ì—…ê·¸ë ˆì´ë“œ
        pip install -U pip setuptools wheel

        # í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­
        pip install -r requirements.txt

        # Unsloth + xformers (ì´ë¯¸ ì„¤ì¹˜í–ˆë‹¤ë©´ ê±´ë„ˆë›°ì–´ë„ OK)
        pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
        pip install --no-deps xformers

        # LLaMA-Factory ìì²´ ì„¤ì¹˜(ê°œë°œëª¨ë“œ) + extras
        pip install -e .[metrics,bitsandbytes,qwen]

        # 1) ì¶©ëŒ ì œê±°
        pip uninstall -y unsloth-zoo datasets

        # 2) LLaMA-Factoryê°€ ìš”êµ¬í•˜ëŠ” ë²”ìœ„ë¡œ ê³ ì • (4.0.0)
        pip install "datasets==4.0.0"
        ```
        -
    - í™˜ê²½ ì²´í¬ (ì˜µì…˜)
        ```bash
        python - << 'PY'
        import sys, torch
        import transformers, accelerate, peft
        import datasets
        print("python:", sys.executable)
        print("transformers:", transformers.__version__)
        print("accelerate:", accelerate.__version__)
        print("peft:", peft.__version__)
        print("cuda available:", torch.cuda.is_available())
        print("datasets:", datasets.__version__)
        PY
        ```

4. ë¡œì»¬ ë°ì´í„°ì…‹ ë³µì‚¬
   - ë¡œì»¬ í„°ë¯¸ë„ ì°½ìœ¼ë¡œ ì ‘ì† í›„ ì‹¤í–‰
        ```bash
        # í˜•ì‹
        scp -P <í¬íŠ¸ë²ˆí˜¸> -i ~/.ssh/id_ed25519 {íŒŒì¼ëª…} root@<RunPod_IP>:/workspace/LLaMA-Factory/data/
        # ì˜ˆì‹œ
        scp -P 11969 -i ~/.ssh/id_ed25519 ko_civil_service_inst.json root@66.92.198.178:/workspace/LLaMA-Factory/data/
        ```
    - ëŸ°íŒŸ í„°ë¯¸ë„ í™•ì¸
        ```bash
        ls -l /workspace/LLaMA-Factory/data
        ```
5. ë°ì´í„°ì…‹ ì´ë¦„ ë“±ë¡
    - dataset_info.json ì— ë“±ë¡í•´ì•¼ ì“¸ ìˆ˜ ìˆìŒ
        ```bash
        # í˜„ì¬ ìœ„ì¹˜ /workspace/LLaMa-Factory
        pwd
        vi data/dataset_info.json
        ```
    - ë‹¤ìŒì„ ë¶™ì—¬ ë„£ê¸°
        ```json
        "ko_civil_service_inst": {
            "file_name": "ko_civil_service.inst.json",
            "formatting": "alpaca", 
            "columns": {
                "prompt": "instruction",
                "response": "output",
                "history": "input"
            }
        },
        ```

6. Config ì¶”ê°€
   - íŒŒì¸íŠœë‹ ì˜µì…˜ Config íŒŒì¼ ì¶”ê°€
     - íŒŒì¼ëª… : 
        ```bash
        # ì—ë””í„° ì‹¤í–‰
        vi {íŠœë‹ì˜µì…˜ìœ¼ë¡œíŒŒì¼ëª…}.yaml
        # ì˜ˆì‹œ
        vi llama-3-8b-Instruct-bnb-4bit-lora-ko.yaml
        ```
     - íŒŒì¼ ë‚´ìš© ì‘ì„± or ë¶™ì—¬ë„£ê¸°
       - ì €ì¥ ëª…ë ¹ì–´ : `:wq`
        ```yaml
        model_name_or_path: unsloth/llama-3-8b-Instruct-bnb-4bit
        quantization_bit: 4
        use_unsloth: true

        stage: sft
        do_train: true
        flash_attn: auto
        #use_unsloth: true
        finetuning_type: lora
        lora_target: all
        lora_rank: 8
        lora_alpha: 16
        lora_dropout: 0.05


        dataset_dir: data
        dataset: ko_civil_service_inst
        template: llama3
        cutoff_len: 1024

        preprocessing_num_workers: 8

        output_dir: output/llama-3-8b-Instruct-bnb-4bit/qlora
        #logging_steps: 10
        #save_steps: 500
        plot_loss: true
        overwrite_output_dir: true

        per_device_train_batch_size: 1
        gradient_accumulation_steps: 4
        learning_rate: 1.0e-4
        num_train_epochs: 3.0
        lr_scheduler_type: cosine
        warmup_ratio: 0.1
        bf16: true
        #report_to: none

        seed: 42
        val_size: 0.1
        per_device_eval_batch_size: 1
        eval_strategy: steps
        eval_steps: 100


        do_eval: true
        #eval_strategy: steps
        #eval_steps: 100
        save_strategy: steps
        save_steps: 100
        logging_steps: 20

        load_best_model_at_end: true
        metric_for_best_model: "eval_loss"
        greater_is_better: false

        report_to: ["tensorboard"]
        resize_vocab: true
        upcast_layernorm: true
        ```

7. í•™ìŠµ ì‹œì‘
   - CLI
        ```bash
        # ë‚´ ê²½ë¡œ í™•ì¸
        pwd

        # (ì„ íƒ) ìºì‹œ ê²½ë¡œ ê³ ì •í•´ë‘ë©´ ì¬ì‚¬ìš©ì— ì¢‹ì•„ìš”
        export HF_HOME=/workspace/.cache/huggingface

        # í•™ìŠµ ì‹œì‘
        python -m llamafactory-cli train config/llama3-8b-instruct-bnb-4bit-unsloth.yaml
        ```
    - Config ì¶”ì²œ ì„¤ì •
        ```yaml
        #.yaml íŒŒì¼
        # í‰ê°€/ì €ì¥/ë¡œê¹… ì „ëµ
        do_eval: true
        eval_strategy: steps           # ë˜ëŠ” "epoch"
        eval_steps: 100                # ë°ì´í„°/ìŠ¤í… ê·œëª¨ì— ë§ê²Œ
        save_strategy: steps
        save_steps: 100
        logging_steps: 20

        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥
        load_best_model_at_end: true
        metric_for_best_model: "eval_loss"
        greater_is_better: false

        # ë¡œê¹… ë°±ì—”ë“œ(ì„ íƒ)
        report_to: ["tensorboard"]     # ë˜ëŠ” ["wandb"] ì‚¬ìš© ì‹œ WANDB_API_KEY í•„ìš”

        # í† í¬ë‚˜ì´ì € ê²½ê³  ëŒ€ì‘
        resize_vocab: true

        #(ê¶Œì¥) 4bit í•™ìŠµ ì•ˆì •í™”
        upcast_layernorm: true
        ```
    - Output í™•ì¸
        ```python
        # ì»¤ë§¨ë“œ
        ls -al {configì— ì§€ì •í•œ ouput_dir}
        # ì˜ˆì‹œ
        ls -al /output/llama-3-8b-Instruct-bnb-4bit/qlora
        ```

8. ì¶”ë¡ 
    ```bash
    # ì¸ì ì„¤ì •
    llamafactory-cli chat \
    --model_name_or_path="unsloth/llama-3-8b-Instruct-bnb-4bit" \
    --adapter_name_or_path="output/llama-3-8b-Instruct-bnb-4bit/qlora" \
    --template="llama3" \
    --finetuning_type="lora" \
    --quantization_bit=4 \
    --temperature=0

    # í…ŒìŠ¤íŠ¸ í›„ íˆìŠ¤í† ë¦¬ ì œê±°
    clear

    # ì±— ì¢…ë£Œ
    exit
    ```

9. ëª¨ë¸ ì €ì¥
   - í•™ìŠµëœ Lora adapterë¥¼ base ëª¨ë¸ê³¼ í•©ì³ ì €ì¥
   - ì €ì¥ íŒŒë¼ë¯¸í„°
     - model_name_or_path : base ëª¨ë¸ì„ ì§€ì •, í•™ìŠµ íš¨ìœ¨í™”ë¥¼ ìœ„í•´ ì‚¬ìš©í–ˆë˜ ì–‘ìí™” ëª¨ë¸ì´ ì•„ë‹Œ ì›ë˜ ëª¨ë¸ì„ ì§€ì •
     - adapter_name_or_path: Lora adapterê°€ ì €ì¥ëœ ìœ„ì¹˜
     - template : ëª¨ë¸ì˜ í˜•ì‹
     - finetuning_type: íŒŒì¸íŠœë‹ ë°©ë²•
     - export_dir: ë³‘í•©ëœ ëª¨ë¸ì´ ì €ì¥ë  ìœ„ì¹˜
     - export_size: ëª¨ë¸ì˜ í° ê²½ìš° ë¶„í• ë  í¬ê¸° (GB)
     - export_device: ëª¨ë¸ ë³‘í•©ì„ ì²˜ë¦¬í•  ë””ë°”ì´ìŠ¤ ì§€ì • (cpu and cuda)
     - export_hub_model_id : huggingfaceì— ì—…ë¡œë“œ í•  ê²½ìš° ì•„ì´ë””
    - CLI
        ```bash
        # llama3 ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ í•´ì•¼í•˜ê¸° ë•Œë¬¸ì— ë¼ì´ì„¼ìŠ¤ ë™ì˜
        huggingface-cli login

        # Lora Adapterë¥¼ ë³‘í•©
        llamafactory-cli export \
        --model_name_or_path="meta-llama/Meta-Llama-3-8B-Instruct" \
        --adapter_name_or_path="output/llama-3-8b-Instruct-bnb-4bit/qlora" \
        --template="llama3" \
        --finetuning_type="lora" \
        --export_dir="/output/Meta-Llama-3-8B-Instruct" \
        --export_size=2 \
        --export_device="cpu"

        # ë¶„í•  ì €ì¥ í™•ì¸
        ls -al output/Meta-Llama-3-8B-Instruct/
        ```

10. HuggingFace ëª¨ë¸ ì—…ë¡œë“œ
    - ê°•ì˜ ìë£Œ ì°¸ê³ 



---

## [ë­ê·¸ë˜í”„]

  - ì „ì²´ ì—°ë™ ê°œë…ë„
    ```text
    [ Streamlit UI ]
        â†“ (user_level session_state)
    [ LangGraph App ]
        â†“
    [ Router Node ]
    â””â”€â”€ ë ˆë²¨ë³„ íŒŒë¼ë¯¸í„° (top_k, context_len)
    [ Generate Node ]
    â””â”€â”€ PROMPT_TEMPLATES[level] ê¸°ë°˜ ì‹œìŠ¤í…œ/ìœ ì € í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        â†“
    [ FT ëª¨ë¸ + pgvector ê²€ìƒ‰ ]
        â†“
    [ ê²°ê³¼ + ref ë°˜í™˜ ]
    ```
  - ì°¸ê³  : ![[graph/readme.md]]


