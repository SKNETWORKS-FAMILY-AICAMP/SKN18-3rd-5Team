from __future__ import annotations
import os, sys, io, time, contextlib
import asyncio
from pathlib import Path
from datetime import datetime
import streamlit as st
from pages.app_bootstrap import render_sidebar, render_page_title, PAGE_INFO  # í•„ìˆ˜
from service.crawling.report_crawling import crawl_shinhan_reports
from service.crawling.kospi_top_crawling import do_crawl
from service.fine_tuning.data_cleansing import do_cleansing
from service.fine_tuning.data_chunking import do_chunking
from service.fine_tuning.csv2json import convert
from service.fine_tuning.llama_factory.split_test_train_data import split

# =========================
# ê³µí†µ í˜ì´ì§€ ì„¤ì •
# =========================
st.set_page_config(
    page_title="StockBuddy: Investment Q&A System",
    page_icon="ğŸ¤–",
    layout="wide",
)
render_sidebar()
render_page_title(PAGE_INFO["PDT"], variant="compact")

# ë£¨íŠ¸ ê²½ë¡œ 
APP_ROOT = Path(__file__).resolve().parents[1]
if str(APP_ROOT) not in sys.path:
    sys.path.insert(0, str(APP_ROOT))

# =========================
# ETL
# =========================
ETL_STEPS = ("Extract", "Transform", "Load")
# íŒŒì´í”„ë¼ì¸ í‘œì‹œ ì´ë¦„ê³¼ ë‚´ë¶€ í‚¤ë¥¼ í•¨ê»˜ ì •ì˜í•œë‹¤.
PIPELINES = (
    ("1ï¸âƒ£ RAG êµ¬ì¶•ìš© ETL íŒŒì´í”„ë¼ì¸", "rag"),
    ("2ï¸âƒ£ FineTuningìš© ETL íŒŒì´í”„ë¼ì¸", "finetune"),
)

PIPELINE_STEP_OUTPUTS: dict[str, dict[str, list[str]]] = {
    "rag": {
        "Extract": ["kospi_top100.txt", "kospi_top100_map.json", "data/zip/", "data/xml/", "data/markdown/*"],
        "Transform": ["data/transform/*"],
        "Load": ["pgvector"],
    },
    "finetune": {
        "Extract": ["shinhan_research_2025_playwright.csv"],
        "Transform": ["clean_data.csv", "chunked_data.csv", "csv2json.json"],
        "Load": ["service/fine_tuning/llama_factory/dataset/test.json, train.json"],
    },
}

STEP_OUTPUT_LABELS = {
    "Extract": "Extract ê²°ê³¼ íŒŒì¼/ê²½ë¡œ",
    "Transform": "Transform ê²°ê³¼ íŒŒì¼/ê²½ë¡œ",
    "Load": "Load ê²°ê³¼ â–¶ï¸ ì´ì œ LLaMA Factoryì—ì„œ í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”!",
}

STEP_OUTPUT_ICONS = {
    "Extract": "ğŸ“„",
    "Transform": "ğŸ› ï¸",
    "Load": "ğŸš€",
}

def render() -> None:
    """Render ETL orchestration dashboard."""
    st.subheader("ETL íŒŒì´í”„ë¼ì¸")

    _init_state()
    _render_pipeline_overview()
    st.divider()
    _render_pipeline_controls()
    st.divider()
    _render_logs()


def _init_state() -> None:
    if "etl_logs" not in st.session_state:
        st.session_state.etl_logs = []

def _render_pipeline_overview() -> None:
    st.markdown(
        """
        **ê³µí†µ íŒŒì´í”„ë¼ì¸ ìˆœì„œ** : 1. ë°ì´í„° ìˆ˜ì§‘ (Extract) â–¶ï¸  2. ì •ì œ ë° ì „ì²˜ë¦¬ (Transform)  â–¶ï¸  3. ì ì¬ (Load)
        """
    )

def _render_pipeline_controls() -> None:
    for label, key_prefix in PIPELINES:
        st.markdown(f"### {label}")

        report_count = None
        if key_prefix == "finetune":
            # FineTuning Extractì— í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ë§Œ ì˜µì…˜ íŒ¨ë„ë¡œ ë…¸ì¶œí•œë‹¤.
            st.markdown(
                """
                <style>
                .finetune-report-label {
                    padding-top: 6px;
                }
                div[data-testid="stNumberInput"] input[aria-label="ê¸ˆìœµ ë¦¬í¬íŠ¸ ì¶”ì¶œ ê°œìˆ˜"] {
                    border: 1px solid #d0d0d0;
                    border-radius: 6px;
                    padding: 6px 8px;
                }
                </style>
                """,
                unsafe_allow_html=True,
            )
            with st.container(border=True):
                st.markdown("**[Extractìš© ì˜µì…˜ íŒ¨ë„]**")
                label_col, input_col, _spacer = st.columns([1, 1, 6])
                with label_col:
                    st.markdown(
                        '<div class="finetune-report-label">ê¸ˆìœµ ë¦¬í¬íŠ¸ ì¶”ì¶œ ê°œìˆ˜</div>',
                        unsafe_allow_html=True,
                    )
                with input_col:
                    report_count = st.number_input(
                        "ê¸ˆìœµ ë¦¬í¬íŠ¸ ì¶”ì¶œ ê°œìˆ˜",
                        min_value=1,
                        max_value=999999,
                        value=10,
                        step=1,
                        key=f"{key_prefix}_report_count",
                        label_visibility="collapsed",
                    )

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            if st.button("Extract ì‹¤í–‰", key=f"{key_prefix}_extract", use_container_width=True):
                _handle_step("Extract", label, key_prefix, report_count)
        with col2:
            if st.button("Transform ì‹¤í–‰", key=f"{key_prefix}_transform", use_container_width=True):
                _handle_step("Transform", label, key_prefix, report_count)
        with col3:
            if st.button("Load ì‹¤í–‰", key=f"{key_prefix}_load", use_container_width=True):
                _handle_step("Load", label, key_prefix, report_count)
        with col4:
            if st.button(
                "ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰",
                key=f"{key_prefix}_run_all",
                type="primary",
                use_container_width=True,
            ):
                for step in ETL_STEPS:
                    if not _handle_step(step, label, key_prefix, report_count):
                        break
        st.markdown("")  # spacing


def _render_logs() -> None:
    st.subheader("ì‹¤í–‰ ë¡œê·¸")
    if not st.session_state.etl_logs:
        st.info("ì•„ì§ ì‹¤í–‰ëœ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤. ë²„íŠ¼ì„ ëˆŒëŸ¬ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•´ ë³´ì„¸ìš”.")
        return

    for entry in reversed(st.session_state.etl_logs):
        st.code(entry, language="bash")


def _handle_step(
    step: str,
    pipeline_label: str,
    key_prefix: str,
    report_count: int | None = None,
) -> bool:
    success = True
    # Extract ë‹¨ê³„ëŠ” íŒŒì´í”„ë¼ì¸ ìœ í˜•ì— ë”°ë¼ ì‹¤í–‰ ê²½ë¡œê°€ ë‹¤ë¥´ë‹¤.
    if step == "Extract":
        if key_prefix == "finetune":
            count = int(report_count) if report_count is not None else 10
            success = _run_finetune_extract(pipeline_label, count)
        elif key_prefix == "rag":
            success = _run_rag_extract(pipeline_label)
    elif step == "Transform":
        if key_prefix == "finetune":
            success = _run_finetune_transform(pipeline_label)
    elif step == "Load":
        if key_prefix == "finetune":
            success = _run_finetune_load(pipeline_label)
    if not success:
        return False
    _log_step(step, pipeline_label)
    _render_step_outputs(key_prefix, step)
    return True


def _run_rag_extract(pipeline_label: str) -> bool:
    try:
        # RAG ìš© ETLì€ KOSPI ìƒìœ„ ì¢…ëª© í¬ë¡¤ë§ì„ ìˆ˜í–‰í•œë‹¤.
        _log_info(pipeline_label, "KOSPI ìƒìœ„ ì¢…ëª© ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤...")
        with st.spinner("KOSPI ìƒìœ„ ì¢…ëª© ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
            do_crawl()
    except Exception as exc:  # noqa: BLE001
        _log_error("Extract", pipeline_label, exc)
        st.error(f"RAG Extract ë‹¨ê³„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
        return False
    return True


def _run_finetune_extract(pipeline_label: str, report_count: int = 10) -> bool:
    try:
        # FineTuning ìš© ETLì€ ì…ë ¥ ë°›ì€ ìˆ˜ë§Œí¼ ì‹ í•œ ê¸ˆìœµ ë¦¬í¬íŠ¸ë¥¼ ìˆ˜ì§‘í•œë‹¤.
        _log_info(pipeline_label, f"ê¸ˆìœµ ë¦¬í¬íŠ¸ {report_count}ê±´ì„ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤...")
        with st.spinner(f"ê¸ˆìœµ ë¦¬í¬íŠ¸ {report_count}ê±´ì„ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
            asyncio.run(crawl_shinhan_reports(report_count))
    except Exception as exc:  # noqa: BLE001
        _log_error("Extract", pipeline_label, exc)
        st.error(f"FineTuning Extract ë‹¨ê³„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
        return False
    return True


def _run_finetune_transform(pipeline_label: str) -> bool:
    try:
        _log_info(
            pipeline_label,
            "ì •ì œ â†’ ì²­í¬ ë¶„í•  â†’ JSON ë³€í™˜ ì‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤...",
        )
        with st.spinner("FineTuning Transform ë‹¨ê³„ ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            do_cleansing()
            do_chunking()
            convert()
    except Exception as exc:  # noqa: BLE001
        _log_error("Transform", pipeline_label, exc)
        st.error(f"FineTuning Transform ë‹¨ê³„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
        return False
    return True


def _run_finetune_load(pipeline_label: str) -> bool:
    try:
        _log_info(
            pipeline_label,
            "í•™ìŠµ/í‰ê°€ ë°ì´í„° ë¶„í•  ë° LLaMA Factory ì ì¬ ì¤€ë¹„ë¥¼ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤...",
        )
        with st.spinner("FineTuning Load ë‹¨ê³„ ì‘ì—…ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            split()
    except Exception as exc:  # noqa: BLE001
        _log_error("Load", pipeline_label, exc)
        st.error(f"FineTuning Load ë‹¨ê³„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
        return False
    return True


def _log_step(step: str, pipeline_label: str) -> None:
    _log_info(pipeline_label, f"{step} ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.toast(f"{pipeline_label}: {step} ë‹¨ê³„ ì‹¤í–‰ ì™„ë£Œ!", icon="âœ…")


def _log_info(pipeline_label: str, message: str) -> None:
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.etl_logs.append(f"[{timestamp}] [{pipeline_label}] {message}")


def _log_error(step: str, pipeline_label: str, error: Exception) -> None:
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.etl_logs.append(
        f"[{timestamp}] [{pipeline_label}] {step} ë‹¨ê³„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error}"
    )
    st.toast(f"{pipeline_label}: {step} ë‹¨ê³„ ì‹¤í–‰ ì‹¤íŒ¨", icon="âŒ")


def _render_step_outputs(key_prefix: str, step: str) -> None:
    outputs = PIPELINE_STEP_OUTPUTS.get(key_prefix, {}).get(step)
    if not outputs:
        return

    icon = STEP_OUTPUT_ICONS.get(step, "ğŸ“")
    label = STEP_OUTPUT_LABELS.get(step, "ê²°ê³¼ íŒŒì¼/ê²½ë¡œ")
    bullet_lines = "\n".join(f"- `{item}`" for item in outputs)
    st.markdown(f"{icon} **{label}**\n{bullet_lines}")


if __name__ == "__main__":
    render()
